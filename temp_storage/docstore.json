{"docstore/data": {"757c2867-288a-4c98-98ec-61188b0a52e2": {"__data__": {"id_": "757c2867-288a-4c98-98ec-61188b0a52e2", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "doc_id:0", "node_type": "4", "metadata": {}, "hash": "9e241bbb55a81e809b01f83a00b7499b39b163a62ada3eb1b120a46b11886a36", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "923162c2-cef0-4b34-85ff-3155ad3a30ff", "node_type": "1", "metadata": {}, "hash": "9e92c52939b7c6a3cc3e1e96e3bf631de4d3fbad9b6fea2d9bdcde2b30c8ea96", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Preprint\nTRANSFORMER2: SELF-ADAPTIVE LLM S\nQi Sun1,2*, Edoardo Cetin1*, Yujin Tang1*\n1Sakana AI, Japan2Institute of Science Tokyo, Japan\n{qisun,edo,yujintang }@sakana.ai\n*Equal contribution\nABSTRACT\nSelf-adaptive large language models (LLMs) aim to solve the challenges posed\nby traditional fine-tuning methods, which are often computationally intensive and\nstatic in their ability to handle diverse tasks. We introduce Transformer2, a novel\nself-adaptation framework that adapts LLMs for unseen tasks in real-time by se-\nlectively adjusting only the singular components of their weight matrices. During\ninference, Transformer2employs a two-pass mechanism: first, a dispatch system\nidentifies the task properties, and then task-specific \u201cexpert\u201d vectors, trained using\nreinforcement learning, are dynamically mixed to obtain targeted behavior for the\nincoming prompt. Our method outperforms ubiquitous approaches such as LoRA,\nwith fewer parameters and greater efficiency. Transformer2demonstrates versatil-\nity across different LLM architectures and modalities, including vision-language\ntasks. Transformer2represents a significant leap forward, offering a scalable, ef-\nficient solution for enhancing the adaptability and task-specific performance of\nLLMs, paving the way for truly dynamic, self-organizing AI systems. Our code is\navailable at https://github.com/SakanaAI/self-adaptive-llms\n1 I NTRODUCTION\nSVD of Weights\nSelf-Adaptation VectorsCodingVLM\u2026Dispatch\nUser Query\nHidden States\u201cThis is a math question\u201d\nHidden StatesAnswer to User Query<latexit sha1_base64=\"N1vdtuDDj/v4W8Gh3EJBeDVKdH4=\">AAAB9HicbVBNS8NAEJ34WetX1aOXYCt4KolI9WbBi8cK9gPaWDbbabt0s4m7m0IJ/R2ieFDEq3f/hjf/jZu2B219MPB4b4aZeX7EmdKO820tLa+srq1nNrKbW9s7u7m9/ZoKY0mxSkMeyoZPFHImsKqZ5tiIJJLA51j3B1epXx+iVCwUt3oUoReQnmBdRok2kleo3bWY0Cgp4YV2Lu8UnQnsReLOSP7y8zHFU6Wd+2p1QhoHKDTlRKmm60TaS4jUjHIcZ1uxwojQAelh01BBAlReMjl6bB8bpWN3Q2lKaHui/p5ISKDUKPBNZ0B0X817qfif14x198JLmIhijYJOF3VjbuvQThOwO0wi1XxkCKGSmVtt2ieSUBODypoQ3PmXF0nttOiWiqUbN18+gykycAhHcAIunEMZrqECVaBwDw/wAq/W0Hq23qz3aeuSNZs5gD+wPn4AOWeWLw==</latexit>V|\n<latexit sha1_base64=\"N1vdtuDDj/v4W8Gh3EJBeDVKdH4=\">AAAB9HicbVBNS8NAEJ34WetX1aOXYCt4KolI9WbBi8cK9gPaWDbbabt0s4m7m0IJ/R2ieFDEq3f/hjf/jZu2B219MPB4b4aZeX7EmdKO820tLa+srq1nNrKbW9s7u7m9/ZoKY0mxSkMeyoZPFHImsKqZ5tiIJJLA51j3B1epXx+iVCwUt3oUoReQnmBdRok2kleo3bWY0Cgp4YV2Lu8UnQnsReLOSP7y8zHFU6Wd+2p1QhoHKDTlRKmm60TaS4jUjHIcZ1uxwojQAelh01BBAlReMjl6bB8bpWN3Q2lKaHui/p5ISKDUKPBNZ0B0X817qfif14x198JLmIhijYJOF3VjbuvQThOwO0wi1XxkCKGSmVtt2ieSUBODypoQ3PmXF0nttOiWiqUbN18+gykycAhHcAIunEMZrqECVaBwDw/wAq/W0Hq23qz3aeuSNZs5gD+wPn4AOWeWLw==</latexit>V|\n<latexit sha1_base64=\"eBMAWvMj6r7BRZByVUOzrFT18f0=\">AAAB73icbZC5TgMxEIZnwxXCFY6OxiJBoop2KQIdkSigDIIcUrKKvI6TWLG9i+1FCqu8BA0FCNHSUPEkdJS8Cc5RQMIvWfr0/zPyzAQRZ9q47peTWlhcWl5Jr2bW1jc2t7LbO1UdxorQCgl5qOoB1pQzSSuGGU7rkaJYBJzWgv75KK/dUaVZKG/MIKK+wF3JOoxgY616vnnNugLnW9mcW3DHQvPgTSF39nH/ffG+l5Rb2c9mOySxoNIQjrVueG5k/AQrwwinw0wz1jTCpI+7tGFRYkG1n4znHaJD67RRJ1T2SYPG7u+OBAutByKwlQKbnp7NRuZ/WSM2nVM/YTKKDZVk8lEn5siEaLQ8ajNFieEDC5goZmdFpIcVJsaeKGOP4M2uPA/V44JXLBSvvFzJhYnSsA8HcAQenEAJLqEMFSDA4QGe4Nm5dR6dF+d1Uppypj278EfO2w9IDpMn</latexit>\u2303<latexit sha1_base64=\"eBMAWvMj6r7BRZByVUOzrFT18f0=\">AAAB73icbZC5TgMxEIZnwxXCFY6OxiJBoop2KQIdkSigDIIcUrKKvI6TWLG9i+1FCqu8BA0FCNHSUPEkdJS8Cc5RQMIvWfr0/zPyzAQRZ9q47peTWlhcWl5Jr2bW1jc2t7LbO1UdxorQCgl5qOoB1pQzSSuGGU7rkaJYBJzWgv75KK/dUaVZKG/MIKK+wF3JOoxgY616vnnNugLnW9mcW3DHQvPgTSF39nH/ffG+l5Rb2c9mOySxoNIQjrVueG5k/AQrwwinw0wz1jTCpI+7tGFRYkG1n4znHaJD67RRJ1T2SYPG7u+OBAutByKwlQKbnp7NRuZ/WSM2nVM/YTKKDZVk8lEn5siEaLQ8ajNFieEDC5goZmdFpIcVJsaeKGOP4M2uPA/V44JXLBSvvFzJhYnSsA8HcAQenEAJLqEMFSDA4QGe4Nm5dR6dF+d1Uppypj278EfO2w9IDpMn</latexit>\u2303\n<latexit", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3670, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "923162c2-cef0-4b34-85ff-3155ad3a30ff": {"__data__": {"id_": "923162c2-cef0-4b34-85ff-3155ad3a30ff", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "doc_id:0", "node_type": "4", "metadata": {}, "hash": "9e241bbb55a81e809b01f83a00b7499b39b163a62ada3eb1b120a46b11886a36", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "757c2867-288a-4c98-98ec-61188b0a52e2", "node_type": "1", "metadata": {}, "hash": "58828ad7b162ce263ac162db77cfed0eb2169caf7cc2847a04275e6d2e17eaf7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "edf6cc4a-57f5-475b-8fbc-438978ba2798", "node_type": "1", "metadata": {}, "hash": "122089d15885ef825bdf9c0a1fb47c3c8b872f41683dfc6ae19cab770716d01f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "sha1_base64=\"matz0JW476ILPpVL90CB+3EA69o=\">AAAB6nicbZDNTsJAFIVv8Q/xD3XpZiKYuCKtIehOEjcuMVoggYZMhylMmE6bmakJaXgENy406NaX8DXc+TZOgYWCJ5nkyzn3Zu69fsyZ0rb9beXW1jc2t/LbhZ3dvf2D4uFRU0WJJNQlEY9k28eKciaoq5nmtB1LikOf05Y/usny1iOVikXiQY9j6oV4IFjACNbGui+75V6xZFfsmdAqOAsoXX9OM701esWvbj8iSUiFJhwr1XHsWHsplpoRTieFbqJojMkID2jHoMAhVV46G3WCzozTR0EkzRMazdzfHSkOlRqHvqkMsR6q5Swz/8s6iQ6uvJSJONFUkPlHQcKRjlC2N+ozSYnmYwOYSGZmRWSIJSbaXKdgjuAsr7wKzYuKU6vU7pxSvQpz5eEETuEcHLiEOtxCA1wgMIAneIFXi1vP1tR6n5fmrEXPMfyR9fEDiQqRvg==</latexit>U<latexit sha1_base64=\"matz0JW476ILPpVL90CB+3EA69o=\">AAAB6nicbZDNTsJAFIVv8Q/xD3XpZiKYuCKtIehOEjcuMVoggYZMhylMmE6bmakJaXgENy406NaX8DXc+TZOgYWCJ5nkyzn3Zu69fsyZ0rb9beXW1jc2t/LbhZ3dvf2D4uFRU0WJJNQlEY9k28eKciaoq5nmtB1LikOf05Y/usny1iOVikXiQY9j6oV4IFjACNbGui+75V6xZFfsmdAqOAsoXX9OM701esWvbj8iSUiFJhwr1XHsWHsplpoRTieFbqJojMkID2jHoMAhVV46G3WCzozTR0EkzRMazdzfHSkOlRqHvqkMsR6q5Swz/8s6iQ6uvJSJONFUkPlHQcKRjlC2N+ozSYnmYwOYSGZmRWSIJSbaXKdgjuAsr7wKzYuKU6vU7pxSvQpz5eEETuEcHLiEOtxCA1wgMIAneIFXi1vP1tR6n5fmrEXPMfyR9fEDiQqRvg==</latexit>U\nMathFirst passSecond passElement-wise multiplicationMatrix multiplicationN layers inside an LLM\nFigure 1: Overview of Transformer2.In the training\nphase, we tune the scales of the singular values of the weight\nmatrices to generate a set of \u201cexpert\u201d vectors, each of which\nspecializes in one type of tasks. In the inference phase, a\ntwo-pass process is adopted where the first applies the task-\nspecific expert and the second generates the answer.Self-adaptive large language models\n(LLMs) would represent a significant\nadvancement in artificial intelligence,\nproviding a framework where mod-\nels can adjust to varied tasks and dy-\nnamic contexts in real time. While\ncompositionality and scalability are\ncrucial for effective adaptation, cur-\nrent LLM training methodologies fall\nshort of achieving both these prop-\nerties simultaneously. Our research\naims to present a pioneering solu-\ntion to realize this vision and address\nthese gaps.\nTraditionally, LLM post-training has\nsought to optimize a model for a wide\nrange of capabilities in a single, ex-\ntensive training session. While this\n\u201cone-shot\u201d fine-tuning framework is\nideal from a simplicity perspective, it\nis also difficult to achieve in practice.\nFor instance, post-training is still highly resource-intensive, leading to significant computational\ncosts and training times. Additionally, there tends to be notable performance trade-offs when in-\ntroducing additional breadth to the data, making it challenging to overcome overfitting and task\ninterference at the same time.\nIn contrast, self-adaptive models offer a more flexible and efficient approach. Rather than attempting\nto train an LLM for all tasks in one step, expert modules can be developed offline and augmented\n1arXiv:2501.06252v2  [cs.LG]  14 Jan 2025\nPreprint\nto the base LLM on-demand (Kang et al., 2024). This allows the model to dynamically modify its\nbehavior based on the task at hand, without the need for constant re-tuning. In addition to the bene-\nfit of having independent components, this modularity also supports continual learning, enabling\nthe model to add new skills over time without catastrophic forgetting. Moreover, self-adaptive\nLLMs mirror a well-established principle in neuroscience and computational biology, where the\nbrain activates specific regions depending on the task at hand (Loose et al., 2017) and dynamically\nreconfigures its functional networks in response to changing task demands (Davison et al., 2015).\nIn principle, the first step toward achieving self-adaptive LLMs can be realized through the devel-\nopment of specialized expert modules, each fine-tuned (Kaplan et al., 2020) via techniques such\nas low-rank adaptation (LoRA) (Hu et al., 2021). These expert modules can then be dynamically\ncomposed at runtime based on the task demands, a process that can be efficiently managed through\nMixture of Experts (MoE)-like systems (Tianlong et al., 2024). However, several challenges need to\nbe addressed to make this approach both scalable and compositional. First, fine-tuning LLMs to cre-\nate multiple expert modules significantly increases the number of parameters that need to be trained.\nIn practice, even with parameter-efficient methods like LoRA, the cumulative size of these mod-\nules can quickly escalate, leading to increased storage and computational demands. Second, these\nexpert modules are often prone to overfitting, a phenomenon especially prevalent when training on\nsmaller datasets or narrow task domains. Third, the flexible composition of these expert modules\nalso presents largely unresolved challenges currently posing as open research problems.\nTo overcome these limitations, we first propose Singular Value Fine-tuning (SVF), a novel\nparameter-efficient fine-tuning (PEFT) method to obtain effective building blocks for self-\nadaptation. SVF works by extracting and tuning only the singular values within the model\u2019s weight\nmatrices. By focusing on this principled parameterization, our approach mitigates the risk of over-\nfitting, drastically reduces computational demands, and allows for inherent compositionality. We\nshow these properties enable us to cheaply obtain a set of effective domain-specific \u201cexpert\u201d vectors\nby training on narrow datasets with RL, directly optimizing task performance on individual topics.\nWe then introduce our full Transformer2framework to empower LLMs through the underlying prin-\nciples of self-adaptation. Given a prompt from an unknown task, Transformer2entails a two-pass\ninference mechanism which we illustrate in Figure 1. During the first pass, Transformer2executes\nthe model and observes its test-time behavior, gathering the relevant information to understand the\nnecessary skills to tackle the current problem. During the second pass, our framework uses this infor-\nmation to combine the available expert vectors and provide a new modification to the base weights\nof the LLM specifically tailored to its test-time conditions. We design three different adaptation\nstrategies that can be used within Transformer2, which we show provide monotonic performance\nbenefits with increasing access to the test-time conditions.\nWe evaluate SVF and the full Transformer2framework through extensive experiments across a di-\nverse range of LLMs and tasks. First, when trained on domain-specific datasets, we show that SVF\nconsistently outperforms traditional strategies for efficient fine-tuning such as LoRA, and at the\nsame time, with orders of magnitudes fewer parameters. Then we show that Transformer2is able\nto push performance far further, effectively adapting the weights of the base model even in entirely\nout-of-distribution applications such as visual question answering. Finally, we analyze the proper-\nties of our new framework, validating that it provides increasing benefits with additional access to\nits current test-time conditions and even allow for recycling pre-trained SVF experts across model\narchitectures. In summary, our key technical contributions are the following:\n\u2022 The development of Transformer2as a pivotal self-adaptation framework for LLMs, pro-\nviding a universal blueprint to dynamically adapt the behavior of LLMs from a growing set\nof pre-trained skills.", "mimetype": "text/plain", "start_char_idx": 3671, "end_char_idx": 10910, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "edf6cc4a-57f5-475b-8fbc-438978ba2798": {"__data__": {"id_": "edf6cc4a-57f5-475b-8fbc-438978ba2798", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "doc_id:0", "node_type": "4", "metadata": {}, "hash": "9e241bbb55a81e809b01f83a00b7499b39b163a62ada3eb1b120a46b11886a36", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "923162c2-cef0-4b34-85ff-3155ad3a30ff", "node_type": "1", "metadata": {}, "hash": "9e92c52939b7c6a3cc3e1e96e3bf631de4d3fbad9b6fea2d9bdcde2b30c8ea96", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "336b34d3-4aed-47d7-98cd-07aa170ed338", "node_type": "1", "metadata": {}, "hash": "1ecbf6430bbfc6a66e20390f6d0551286cd637ed38fc33c6b861cb2749bfcf1a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "First, when trained on domain-specific datasets, we show that SVF\nconsistently outperforms traditional strategies for efficient fine-tuning such as LoRA, and at the\nsame time, with orders of magnitudes fewer parameters. Then we show that Transformer2is able\nto push performance far further, effectively adapting the weights of the base model even in entirely\nout-of-distribution applications such as visual question answering. Finally, we analyze the proper-\nties of our new framework, validating that it provides increasing benefits with additional access to\nits current test-time conditions and even allow for recycling pre-trained SVF experts across model\narchitectures. In summary, our key technical contributions are the following:\n\u2022 The development of Transformer2as a pivotal self-adaptation framework for LLMs, pro-\nviding a universal blueprint to dynamically adapt the behavior of LLMs from a growing set\nof pre-trained skills.\n\u2022 The introduction of SVF, a novel PEFT method trainable with RL on small datasets, pro-\nducing compact expert vectors with inherent compositionality, all key properties necessary\nfor our scalable self-adaptation framework.\n\u2022 The implementation of three adaptation strategies within Transformer2, effectively dis-\npatching SVF-trained experts with properties designed to cope with different requirements\nand deployment scenarios.\n2\nPreprint\n2 R ELATED WORKS\nSelf-adaptive LLMs We define self-adaptive LLMs as a group of LLMs or a standalone LLM\nthat can evaluate and modify its behavior in response to changes in its operating environment or\ninternal state, without external intervention. This adaptation can be explored from two perspectives:\na macroview, where multiple LLMs collaborate and/or compete, and a microview, where internal\nadaptations allow a single LLM to specialize in different tasks.\nMacroview: From this perspective, the system directs queries to LLMs with domain specific exper-\ntise, prioritizing outputs from expert models, thereby achieving higher accuracy and task-specific\noptimization. Such task-specific ensembles can be realized through various mechanisms: multiple\nLLMs playing distinct roles and coordinate toward a shared goal (Zhuge et al., 2023), engaging\nin mutual listening and debate (Du et al., 2023), or using meticulously crafted prompt construc-\ntions (Zhang et al., 2024) to integrate knowledge library and skill planning. Naturally, the improve-\nment in the specialization and adaptive capabilities of individual LLMs in the ensemble enhances\nthe collective performance. Thus, in this paper, we focus on the microview of self-adaptive LLMs.\nMicroview: MoE in LLMs plays a critical role in this perspective (Tianlong et al., 2024). In MoE\nsystems, inputs are dynamically routed to a subset of specialized modules or layers (e.g., MLPs)\ncontaining domain-specific knowledge (Rajbhandari et al., 2022; Fedus et al., 2022). To reduce\ninference time, researchers introduce sparsely activated MoE where only a subset of the experts are\nselected per token Jiang et al. (2024); Qwen Team (2024). While it is possible to view Transformer2\nloosely as a type of MoE, there are two major differences. In the aforementioned systems, self-\nadaptation is achieved through token-level routing, whereas Transformer2employs a sample-level\nmodule selection strategy. The second difference lies in the construction of expert modules. In\ntraditional MoE systems, expert modules are either trained from scratch (Fedus et al., 2022; Jiang\net al., 2024) or dense models (e.g., upcycling) (Qwen Team, 2024; Zhu et al., 2024), without an\nauxiliary loss to ensure module specialization. In contrast, Transformer2specifically trains expert\nvectors with RL to acquire domain specific-knowledge, making them true experts.\nLow-rank adaptation PEFT methods such as LoRA (Hu et al., 2021) works by freezing the original\nmodel\u2019s parameters and introducing small trainable low-rank matrices for task-specific updates. It\nsignificantly lowers the computational and memory costs while providing performance comparable\nto full fine-tuning. Inspired by LoRA\u2019s design, various modifications have been proposed (Zhang\net al., 2023; Kopiczko et al., 2023; Liu et al., 2024; Ba\u0142azy et al., 2024; Cetoli, 2024). Transformer2\ndoes not rely on low-rank matrices, and instead scales the singular vectors of the original parameter\nmatrix that span the full rank space.\nSVD for LLM Fine-tuning SVD is increasingly being used as an inductive bias for PEFT in LLMs.\nFor example, Wang et al. (2024) decompose a weight matrix and use the minor singular components,\nassociated with noisy or long-tail information, to initialize low-rank matrices for LoRA fine-tuning.\nIn a similar vein, SVD is employed to approximate an original weight matrix with the top rsingular\nvectors, corresponding to the highest singular values. A small trainable matrix is then introduced\non top of the truncated singular value matrix to adjust the magnitude and orientations within this\ntop-rsubspace (Ba\u0142azy et al., 2024; Cetoli, 2024). However, the drawback of this approach is\nthat retaining only the top singular components can result in the loss of important information,\nparticularly when the singular values distribution is less skewed. The work most similar to ours is a\nconcurrent effort by Lingam et al. (2024), where they introduce various sparsification methods that\nutilize the SVD of the weights. However, it is not for self-adaptive LLMs and does not use RL to\nenhance learning efficiency.\n3 M ETHODS\n3.1 P RELIMINARIES\nSingular value decomposition (SVD) offers a fundamental view of matrix multiplications. In the\ncontext of neural networks, each weight matrix W\u2208Rn\u00d7mcan be decomposed into three compo-\nnents W=U\u03a3V\u22ba, yielding semi-orthogonal matrices U\u2208Rm\u00d7randV\u2208Rn\u00d7rtogether with an\nordered vector of rsingular values (in descending order) arranged in the diagonal matrix \u03a3\u2208Rr\u00d7r.\nThe linear operation defined by applying Wontox, can be then decomposed into a sum of indepen-\n3\nPreprint\ndent terms, derived from mapping each column vifrom Vinto the corresponding column uifrom\nUasy=Pr\ni=1\u03c3iuiv\u22ba\nix. Hence, each singular component represented by the rank-1 matrix uiv\u22ba\ni\nindependently processes the input, providing an orthogonal contribution to the layer\u2019s outputs, with\nthe singular values \u03c3imodulating the degree of the contributions.\nCross-entropy method (CEM) is a Monte Carlo method for importance sampling and optimiza-\ntion (Rubinstein & Kroese, 2004). The method is based on the concept of minimizing the KL\ndivergence between two probability distributions DKL(P\u2225Q), where Pis the target distribution and\nQis a maintained distribution. At its core, CEM repeatedly generates a set of samples from Q,\nevaluates these samples with a performance function, and then updates the distribution Qwith the\ncharacteristics of the elite samples that have performed best. In the standard setup employed in most\napplications, Qis set to a diagonal multivariate Gaussian, reducing the problem to simply estimating\nthe empirical mean and standard deviation of the latest elites until a stopping criterion is met. We\nillustrate a complete CEM step in the Python pseudocode below.\n3.2 T RANSFORMER2\nThe construction of Transformer2comprises two main steps, for which we provide an illustrative\noverview in Figure 2. First, we introduce Singular Value Fine-tuning (SVF), a method to learn\nwith RL compact and compositional expert vectors based on the SVD of the base model\u2019s weights.\nThen, we describe three different adaptation strategies within Transformer2, inspired by three or-\nthogonal principles, which adaptively combine the SVF-trained expert vectors during inference. We\nmotivate how the properties of SVF are highly complementary to our adaptation strategies, making\nTransformer2an effective and scalable framework for the design of new self-adaptive LLMs.\nLayer Norm<latexit", "mimetype": "text/plain", "start_char_idx": 9974, "end_char_idx": 17867, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "336b34d3-4aed-47d7-98cd-07aa170ed338": {"__data__": {"id_": "336b34d3-4aed-47d7-98cd-07aa170ed338", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "doc_id:0", "node_type": "4", "metadata": {}, "hash": "9e241bbb55a81e809b01f83a00b7499b39b163a62ada3eb1b120a46b11886a36", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "edf6cc4a-57f5-475b-8fbc-438978ba2798", "node_type": "1", "metadata": {}, "hash": "122089d15885ef825bdf9c0a1fb47c3c8b872f41683dfc6ae19cab770716d01f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5e7b79c7-175f-4355-b915-20890b57462b", "node_type": "1", "metadata": {}, "hash": "1b2b392f8a9251b9b21f950a726cceda949a6f54b3e1c6ddb2f56508c50d6c6c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "We\nillustrate a complete CEM step in the Python pseudocode below.\n3.2 T RANSFORMER2\nThe construction of Transformer2comprises two main steps, for which we provide an illustrative\noverview in Figure 2. First, we introduce Singular Value Fine-tuning (SVF), a method to learn\nwith RL compact and compositional expert vectors based on the SVD of the base model\u2019s weights.\nThen, we describe three different adaptation strategies within Transformer2, inspired by three or-\nthogonal principles, which adaptively combine the SVF-trained expert vectors during inference. We\nmotivate how the properties of SVF are highly complementary to our adaptation strategies, making\nTransformer2an effective and scalable framework for the design of new self-adaptive LLMs.\nLayer Norm<latexit sha1_base64=\"hnfzLeUw92WJ9yYUkRkk/DJmo2g=\">AAAB8nicbZDLSgMxFIYzXmu9VV26CRbBVZkRqe4suHFZwV5gOpZMmmlDM8mQnBHK0MdwYReKuPUFfA13vo2Ztgtt/SHw8f/nkHNOmAhuwHW/nZXVtfWNzcJWcXtnd2+/dHDYNCrVlDWoEkq3Q2KY4JI1gINg7UQzEoeCtcLhTZ63Hpk2XMl7GCUsiElf8ohTAtbymw8dLoFpSkS3VHYr7lR4Gbw5lK8/n3NN6t3SV6enaBozCVQQY3zPTSDIiAZOBRsXO6lhCaFD0me+RUliZoJsOvIYn1qnhyOl7ZOAp+7vjozExozi0FbGBAZmMcvN/zI/hegqyLhMUmCSzj6KUoFB4Xx/3OOaURAjC4RqbmfFdEA0ofYKpmiP4C2uvAzN84pXrVTvvHLtAs1UQMfoBJ0hD12iGrpFddRAFCn0hF7QqwPOxHlz3melK8685wj9kfPxA3w0ldM=</latexit>V|\n<latexit sha1_base64=\"hnfzLeUw92WJ9yYUkRkk/DJmo2g=\">AAAB8nicbZDLSgMxFIYzXmu9VV26CRbBVZkRqe4suHFZwV5gOpZMmmlDM8mQnBHK0MdwYReKuPUFfA13vo2Ztgtt/SHw8f/nkHNOmAhuwHW/nZXVtfWNzcJWcXtnd2+/dHDYNCrVlDWoEkq3Q2KY4JI1gINg7UQzEoeCtcLhTZ63Hpk2XMl7GCUsiElf8ohTAtbymw8dLoFpSkS3VHYr7lR4Gbw5lK8/n3NN6t3SV6enaBozCVQQY3zPTSDIiAZOBRsXO6lhCaFD0me+RUliZoJsOvIYn1qnhyOl7ZOAp+7vjozExozi0FbGBAZmMcvN/zI/hegqyLhMUmCSzj6KUoFB4Xx/3OOaURAjC4RqbmfFdEA0ofYKpmiP4C2uvAzN84pXrVTvvHLtAs1UQMfoBJ0hD12iGrpFddRAFCn0hF7QqwPOxHlz3melK8685wj9kfPxA3w0ldM=</latexit>V|\n<latexit sha1_base64=\"8jULmK0JRDiG/w9c6wlV1jj7guI=\">AAAB7XicbZC7SgNBFIbPxluMt6ilIINBSBV2LaKdARvLBM0FkhBmJ7PJmNmZZWZWCEtKexsLRWztrPMcdj6DL+HkUmjiDwMf/38Oc87xI860cd0vJ7Wyura+kd7MbG3v7O5l9w9qWsaK0CqRXKqGjzXlTNCqYYbTRqQoDn1O6/7gapLX76nSTIpbM4xoO8Q9wQJGsLFWrXXDeiHuZHNuwZ0KLYM3h9zlx7jy/XA8Lneyn62uJHFIhSEca9303Mi0E6wMI5yOMq1Y0wiTAe7RpkWBQ6rbyXTaETq1ThcFUtknDJq6vzsSHGo9DH1bGWLT14vZxPwva8YmuGgnTESxoYLMPgpijoxEk9VRlylKDB9awEQxOysifawwMfZAGXsEb3HlZaidFbxioVjxcqU8zJSGIziBPHhwDiW4hjJUgcAdPMIzvDjSeXJenbdZacqZ9xzCHznvPxkHky0=</latexit>\u2303<latexit sha1_base64=\"8jULmK0JRDiG/w9c6wlV1jj7guI=\">AAAB7XicbZC7SgNBFIbPxluMt6ilIINBSBV2LaKdARvLBM0FkhBmJ7PJmNmZZWZWCEtKexsLRWztrPMcdj6DL+HkUmjiDwMf/38Oc87xI860cd0vJ7Wyura+kd7MbG3v7O5l9w9qWsaK0CqRXKqGjzXlTNCqYYbTRqQoDn1O6/7gapLX76nSTIpbM4xoO8Q9wQJGsLFWrXXDeiHuZHNuwZ0KLYM3h9zlx7jy/XA8Lneyn62uJHFIhSEca9303Mi0E6wMI5yOMq1Y0wiTAe7RpkWBQ6rbyXTaETq1ThcFUtknDJq6vzsSHGo9DH1bGWLT14vZxPwva8YmuGgnTESxoYLMPgpijoxEk9VRlylKDB9awEQxOysifawwMfZAGXsEb3HlZaidFbxioVjxcqU8zJSGIziBPHhwDiW4hjJUgcAdPMIzvDjSeXJenbdZacqZ9xzCHznvPxkHky0=</latexit>\u2303\n<latexit sha1_base64=\"ka/WwxC9Nk0i99aMsQm1DvJgrg0=\">AAAB6HicbZDPTsJAEMan+A/xH+rRSyMx8URaY9CbJF48QmKBBBqyXaawst02u1sTQngCLx40Bo++ha/hzbdxCxwU/JJNfvm+mezMBAlnSjvOt5VbW9/Y3MpvF3Z29/YPiodHDRWnkqJHYx7LVkAUcibQ00xzbCUSSRRwbAbD2yxvPqJULBb3epSgH5G+YCGjRBur7nWLJafszGSvgruA0s3nNNN7rVv86vRimkYoNOVEqbbrJNofE6kZ5TgpdFKFCaFD0se2QUEiVP54NujEPjNOzw5jaZ7Q9sz93TEmkVKjKDCVEdEDtZxl5n9ZO9XhtT9mIkk1Cjr/KEy5rWM729ruMYlU85EBQiUzs9p0QCSh2tymYI7gLq+8Co2LslspV+puqXoJc+XhBE7hHFy4gircQQ08oIDwBC/waj1Yz9abNZ2X5qxFzzH8kfXxA9F0kWI=</latexit>U<latexit", "mimetype": "text/plain", "start_char_idx": 17097, "end_char_idx": 20487, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5e7b79c7-175f-4355-b915-20890b57462b": {"__data__": {"id_": "5e7b79c7-175f-4355-b915-20890b57462b", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "doc_id:0", "node_type": "4", "metadata": {}, "hash": "9e241bbb55a81e809b01f83a00b7499b39b163a62ada3eb1b120a46b11886a36", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "336b34d3-4aed-47d7-98cd-07aa170ed338", "node_type": "1", "metadata": {}, "hash": "1ecbf6430bbfc6a66e20390f6d0551286cd637ed38fc33c6b861cb2749bfcf1a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "af4c0231-33c8-4dd3-a0b5-fa6c8e21ce21", "node_type": "1", "metadata": {}, "hash": "d56e8c0e78e03fd0bdb26ec6a722aa01aa64ba4067011b72556d7a0b58908fc4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "sha1_base64=\"ka/WwxC9Nk0i99aMsQm1DvJgrg0=\">AAAB6HicbZDPTsJAEMan+A/xH+rRSyMx8URaY9CbJF48QmKBBBqyXaawst02u1sTQngCLx40Bo++ha/hzbdxCxwU/JJNfvm+mezMBAlnSjvOt5VbW9/Y3MpvF3Z29/YPiodHDRWnkqJHYx7LVkAUcibQ00xzbCUSSRRwbAbD2yxvPqJULBb3epSgH5G+YCGjRBur7nWLJafszGSvgruA0s3nNNN7rVv86vRimkYoNOVEqbbrJNofE6kZ5TgpdFKFCaFD0se2QUEiVP54NujEPjNOzw5jaZ7Q9sz93TEmkVKjKDCVEdEDtZxl5n9ZO9XhtT9mIkk1Cjr/KEy5rWM729ruMYlU85EBQiUzs9p0QCSh2tymYI7gLq+8Co2LslspV+puqXoJc+XhBE7hHFy4gircQQ08oIDwBC/waj1Yz9abNZ2X5qxFzzH8kfXxA9F0kWI=</latexit>UAttentionLayer NormMLP<latexit sha1_base64=\"WPTq7ovTCCel7T147D53/f38NRg=\">AAAB6HicbZC7SgNBFIbPxluMt3jpbAaDYBV2LaKdAQutJAFzgWQJs5OzyZjZCzOzQlzyBDYWitj6AFY+iZ2lb+LkUmj0h4GP/z+HOed4seBK2/anlVlYXFpeya7m1tY3Nrfy2zt1FSWSYY1FIpJNjyoUPMSa5lpgM5ZIA09gwxucj/PGLUrFo/BaD2N0A9oLuc8Z1caqXnXyBbtoT0T+gjODwtn73dfF215a6eQ/2t2IJQGGmgmqVMuxY+2mVGrOBI5y7URhTNmA9rBlMKQBKjedDDoih8bpEj+S5oWaTNyfHSkNlBoGnqkMqO6r+Wxs/pe1Eu2fuikP40RjyKYf+YkgOiLjrUmXS2RaDA1QJrmZlbA+lZRpc5ucOYIzv/JfqB8XnVKxVHUKZRumysI+HMAROHACZbiECtSAAcI9PMKTdWM9WM/Wy7Q0Y816duGXrNdvyOqQmg==</latexit>N<latexit sha1_base64=\"WPTq7ovTCCel7T147D53/f38NRg=\">AAAB6HicbZC7SgNBFIbPxluMt3jpbAaDYBV2LaKdAQutJAFzgWQJs5OzyZjZCzOzQlzyBDYWitj6AFY+iZ2lb+LkUmj0h4GP/z+HOed4seBK2/anlVlYXFpeya7m1tY3Nrfy2zt1FSWSYY1FIpJNjyoUPMSa5lpgM5ZIA09gwxucj/PGLUrFo/BaD2N0A9oLuc8Z1caqXnXyBbtoT0T+gjODwtn73dfF215a6eQ/2t2IJQGGmgmqVMuxY+2mVGrOBI5y7URhTNmA9rBlMKQBKjedDDoih8bpEj+S5oWaTNyfHSkNlBoGnqkMqO6r+Wxs/pe1Eu2fuikP40RjyKYf+YkgOiLjrUmXS2RaDA1QJrmZlbA+lZRpc5ucOYIzv/JfqB8XnVKxVHUKZRumysI+HMAROHACZbiECtSAAcI9PMKTdWM9WM/Wy7Q0Y816duGXrNdvyOqQmg==</latexit>N layers<latexit sha1_base64=\"yC9X/vIczvf0cNc9NaHz45Lo31s=\">AAAB6HicbZC7SgNBFIbPxluMt6ilIItBSBV2LaKdARvLBMwFkxBmJ2eTMbOzy8ysEJaUVjYWitj6ANZ5DjufwZdwcik08YeBj/8/hznneBFnSjvOl5VaWV1b30hvZra2d3b3svsHNRXGkmKVhjyUDY8o5ExgVTPNsRFJJIHHse4NriZ5/R6lYqG40cMI2wHpCeYzSrSxKredbM4pOFPZy+DOIXf5Ma58PxyPy53sZ6sb0jhAoSknSjVdJ9LthEjNKMdRphUrjAgdkB42DQoSoGon00FH9qlxurYfSvOEtqfu746EBEoNA89UBkT31WI2Mf/LmrH2L9oJE1GsUdDZR37MbR3ak63tLpNINR8aIFQyM6tN+0QSqs1tMuYI7uLKy1A7K7jFQrHi5kp5mCkNR3ACeXDhHEpwDWWoAgWER3iGF+vOerJerbdZacqa9xzCH1nvP2ZpkQg=</latexit>Z<latexit sha1_base64=\"yC9X/vIczvf0cNc9NaHz45Lo31s=\">AAAB6HicbZC7SgNBFIbPxluMt6ilIItBSBV2LaKdARvLBMwFkxBmJ2eTMbOzy8ysEJaUVjYWitj6ANZ5DjufwZdwcik08YeBj/8/hznneBFnSjvOl5VaWV1b30hvZra2d3b3svsHNRXGkmKVhjyUDY8o5ExgVTPNsRFJJIHHse4NriZ5/R6lYqG40cMI2wHpCeYzSrSxKredbM4pOFPZy+DOIXf5Ma58PxyPy53sZ6sb0jhAoSknSjVdJ9LthEjNKMdRphUrjAgdkB42DQoSoGon00FH9qlxurYfSvOEtqfu746EBEoNA89UBkT31WI2Mf/LmrH2L9oJE1GsUdDZR37MbR3ak63tLpNINR8aIFQyM6tN+0QSqs1tMuYI7uLKy1A7K7jFQrHi5kp5mCkNR3ACeXDhHEpwDWWoAgWER3iGF+vOerJerbdZacqa9xzCH1nvP2ZpkQg=</latexit>ZLearnable parameterstrained with RLFrozen parameters\nTraining TimeInference Time\n<latexit", "mimetype": "text/plain", "start_char_idx": 20488, "end_char_idx": 23204, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "af4c0231-33c8-4dd3-a0b5-fa6c8e21ce21": {"__data__": {"id_": "af4c0231-33c8-4dd3-a0b5-fa6c8e21ce21", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "doc_id:0", "node_type": "4", "metadata": {}, "hash": "9e241bbb55a81e809b01f83a00b7499b39b163a62ada3eb1b120a46b11886a36", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5e7b79c7-175f-4355-b915-20890b57462b", "node_type": "1", "metadata": {}, "hash": "1b2b392f8a9251b9b21f950a726cceda949a6f54b3e1c6ddb2f56508c50d6c6c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "260566b6-43d9-46bf-a1a0-532055392d9f", "node_type": "1", "metadata": {}, "hash": "0b061e0ab070e759c90075b78ed08a52d200073aa731cb45c94df1e326de7674", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "parameterstrained with RLFrozen parameters\nTraining TimeInference Time\n<latexit sha1_base64=\"Zy7mRheCx49r7k9l9pfYkhWF0qk=\">AAAB6HicbZC7SgNBFIbPxluMt3jpbAaDYBV2LaKdAQtthATMBZIlzE7OJmNmL8zMCnHJE9hYKGLrA1j5JHaWvomTS6HRHwY+/v8c5pzjxYIrbdufVmZhcWl5JbuaW1vf2NzKb+/UVZRIhjUWiUg2PapQ8BBrmmuBzVgiDTyBDW9wPs4btygVj8JrPYzRDWgv5D5nVBuretXJF+yiPRH5C84MCmfvd18Xb3tppZP/aHcjlgQYaiaoUi3HjrWbUqk5EzjKtROFMWUD2sOWwZAGqNx0MuiIHBqnS/xImhdqMnF/dqQ0UGoYeKYyoLqv5rOx+V/WSrR/6qY8jBONIZt+5CeC6IiMtyZdLpFpMTRAmeRmVsL6VFKmzW1y5gjO/Mp/oX5cdErFUtUplG2YKgv7cABH4MAJlOESKlADBgj38AhP1o31YD1bL9PSjDXr2YVfsl6/AcdmkJk=</latexit>M<latexit sha1_base64=\"Zy7mRheCx49r7k9l9pfYkhWF0qk=\">AAAB6HicbZC7SgNBFIbPxluMt3jpbAaDYBV2LaKdAQtthATMBZIlzE7OJmNmL8zMCnHJE9hYKGLrA1j5JHaWvomTS6HRHwY+/v8c5pzjxYIrbdufVmZhcWl5JbuaW1vf2NzKb+/UVZRIhjUWiUg2PapQ8BBrmmuBzVgiDTyBDW9wPs4btygVj8JrPYzRDWgv5D5nVBuretXJF+yiPRH5C84MCmfvd18Xb3tppZP/aHcjlgQYaiaoUi3HjrWbUqk5EzjKtROFMWUD2sOWwZAGqNx0MuiIHBqnS/xImhdqMnF/dqQ0UGoYeKYyoLqv5rOx+V/WSrR/6qY8jBONIZt+5CeC6IiMtyZdLpFpMTRAmeRmVsL6VFKmzW1y5gjO/Mp/oX5cdErFUtUplG2YKgv7cABH4MAJlOESKlADBgj38AhP1o31YD1bL9PSjDXr2YVfsl6/AcdmkJk=</latexit>M matrices<latexit sha1_base64=\"hnfzLeUw92WJ9yYUkRkk/DJmo2g=\">AAAB8nicbZDLSgMxFIYzXmu9VV26CRbBVZkRqe4suHFZwV5gOpZMmmlDM8mQnBHK0MdwYReKuPUFfA13vo2Ztgtt/SHw8f/nkHNOmAhuwHW/nZXVtfWNzcJWcXtnd2+/dHDYNCrVlDWoEkq3Q2KY4JI1gINg7UQzEoeCtcLhTZ63Hpk2XMl7GCUsiElf8ohTAtbymw8dLoFpSkS3VHYr7lR4Gbw5lK8/n3NN6t3SV6enaBozCVQQY3zPTSDIiAZOBRsXO6lhCaFD0me+RUliZoJsOvIYn1qnhyOl7ZOAp+7vjozExozi0FbGBAZmMcvN/zI/hegqyLhMUmCSzj6KUoFB4Xx/3OOaURAjC4RqbmfFdEA0ofYKpmiP4C2uvAzN84pXrVTvvHLtAs1UQMfoBJ0hD12iGrpFddRAFCn0hF7QqwPOxHlz3melK8685wj9kfPxA3w0ldM=</latexit>V|\n<latexit sha1_base64=\"hnfzLeUw92WJ9yYUkRkk/DJmo2g=\">AAAB8nicbZDLSgMxFIYzXmu9VV26CRbBVZkRqe4suHFZwV5gOpZMmmlDM8mQnBHK0MdwYReKuPUFfA13vo2Ztgtt/SHw8f/nkHNOmAhuwHW/nZXVtfWNzcJWcXtnd2+/dHDYNCrVlDWoEkq3Q2KY4JI1gINg7UQzEoeCtcLhTZ63Hpk2XMl7GCUsiElf8ohTAtbymw8dLoFpSkS3VHYr7lR4Gbw5lK8/n3NN6t3SV6enaBozCVQQY3zPTSDIiAZOBRsXO6lhCaFD0me+RUliZoJsOvIYn1qnhyOl7ZOAp+7vjozExozi0FbGBAZmMcvN/zI/hegqyLhMUmCSzj6KUoFB4Xx/3OOaURAjC4RqbmfFdEA0ofYKpmiP4C2uvAzN84pXrVTvvHLtAs1UQMfoBJ0hD12iGrpFddRAFCn0hF7QqwPOxHlz3melK8685wj9kfPxA3w0ldM=</latexit>V|\n<latexit sha1_base64=\"8jULmK0JRDiG/w9c6wlV1jj7guI=\">AAAB7XicbZC7SgNBFIbPxluMt6ilIINBSBV2LaKdARvLBM0FkhBmJ7PJmNmZZWZWCEtKexsLRWztrPMcdj6DL+HkUmjiDwMf/38Oc87xI860cd0vJ7Wyura+kd7MbG3v7O5l9w9qWsaK0CqRXKqGjzXlTNCqYYbTRqQoDn1O6/7gapLX76nSTIpbM4xoO8Q9wQJGsLFWrXXDeiHuZHNuwZ0KLYM3h9zlx7jy/XA8Lneyn62uJHFIhSEca9303Mi0E6wMI5yOMq1Y0wiTAe7RpkWBQ6rbyXTaETq1ThcFUtknDJq6vzsSHGo9DH1bGWLT14vZxPwva8YmuGgnTESxoYLMPgpijoxEk9VRlylKDB9awEQxOysifawwMfZAGXsEb3HlZaidFbxioVjxcqU8zJSGIziBPHhwDiW4hjJUgcAdPMIzvDjSeXJenbdZacqZ9xzCHznvPxkHky0=</latexit>\u2303<latexit", "mimetype": "text/plain", "start_char_idx": 23125, "end_char_idx": 25836, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "260566b6-43d9-46bf-a1a0-532055392d9f": {"__data__": {"id_": "260566b6-43d9-46bf-a1a0-532055392d9f", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "doc_id:0", "node_type": "4", "metadata": {}, "hash": "9e241bbb55a81e809b01f83a00b7499b39b163a62ada3eb1b120a46b11886a36", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "af4c0231-33c8-4dd3-a0b5-fa6c8e21ce21", "node_type": "1", "metadata": {}, "hash": "d56e8c0e78e03fd0bdb26ec6a722aa01aa64ba4067011b72556d7a0b58908fc4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e759f545-6501-4a67-84a6-f026dd5c6e9d", "node_type": "1", "metadata": {}, "hash": "8e7c219557ac5b01c5eed0ae9a0876d1802dccd0fbd313f481213d00ef348c4d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "sha1_base64=\"8jULmK0JRDiG/w9c6wlV1jj7guI=\">AAAB7XicbZC7SgNBFIbPxluMt6ilIINBSBV2LaKdARvLBM0FkhBmJ7PJmNmZZWZWCEtKexsLRWztrPMcdj6DL+HkUmjiDwMf/38Oc87xI860cd0vJ7Wyura+kd7MbG3v7O5l9w9qWsaK0CqRXKqGjzXlTNCqYYbTRqQoDn1O6/7gapLX76nSTIpbM4xoO8Q9wQJGsLFWrXXDeiHuZHNuwZ0KLYM3h9zlx7jy/XA8Lneyn62uJHFIhSEca9303Mi0E6wMI5yOMq1Y0wiTAe7RpkWBQ6rbyXTaETq1ThcFUtknDJq6vzsSHGo9DH1bGWLT14vZxPwva8YmuGgnTESxoYLMPgpijoxEk9VRlylKDB9awEQxOysifawwMfZAGXsEb3HlZaidFbxioVjxcqU8zJSGIziBPHhwDiW4hjJUgcAdPMIzvDjSeXJenbdZacqZ9xzCHznvPxkHky0=</latexit>\u2303\n<latexit sha1_base64=\"ka/WwxC9Nk0i99aMsQm1DvJgrg0=\">AAAB6HicbZDPTsJAEMan+A/xH+rRSyMx8URaY9CbJF48QmKBBBqyXaawst02u1sTQngCLx40Bo++ha/hzbdxCxwU/JJNfvm+mezMBAlnSjvOt5VbW9/Y3MpvF3Z29/YPiodHDRWnkqJHYx7LVkAUcibQ00xzbCUSSRRwbAbD2yxvPqJULBb3epSgH5G+YCGjRBur7nWLJafszGSvgruA0s3nNNN7rVv86vRimkYoNOVEqbbrJNofE6kZ5TgpdFKFCaFD0se2QUEiVP54NujEPjNOzw5jaZ7Q9sz93TEmkVKjKDCVEdEDtZxl5n9ZO9XhtT9mIkk1Cjr/KEy5rWM729ruMYlU85EBQiUzs9p0QCSh2tymYI7gLq+8Co2LslspV+puqXoJc+XhBE7hHFy4gircQQ08oIDwBC/waj1Yz9abNZ2X5qxFzzH8kfXxA9F0kWI=</latexit>U<latexit sha1_base64=\"ka/WwxC9Nk0i99aMsQm1DvJgrg0=\">AAAB6HicbZDPTsJAEMan+A/xH+rRSyMx8URaY9CbJF48QmKBBBqyXaawst02u1sTQngCLx40Bo++ha/hzbdxCxwU/JJNfvm+mezMBAlnSjvOt5VbW9/Y3MpvF3Z29/YPiodHDRWnkqJHYx7LVkAUcibQ00xzbCUSSRRwbAbD2yxvPqJULBb3epSgH5G+YCGjRBur7nWLJafszGSvgruA0s3nNNN7rVv86vRimkYoNOVEqbbrJNofE6kZ5TgpdFKFCaFD0se2QUEiVP54NujEPjNOzw5jaZ7Q9sz93TEmkVKjKDCVEdEDtZxl5n9ZO9XhtT9mIkk1Cjr/KEy5rWM729ruMYlU85EBQiUzs9p0QCSh2tymYI7gLq+8Co2LslspV+puqXoJc+XhBE7hHFy4gircQQ08oIDwBC/waj1Yz9abNZ2X5qxFzzH8kfXxA9F0kWI=</latexit>U<latexit sha1_base64=\"yC9X/vIczvf0cNc9NaHz45Lo31s=\">AAAB6HicbZC7SgNBFIbPxluMt6ilIItBSBV2LaKdARvLBMwFkxBmJ2eTMbOzy8ysEJaUVjYWitj6ANZ5DjufwZdwcik08YeBj/8/hznneBFnSjvOl5VaWV1b30hvZra2d3b3svsHNRXGkmKVhjyUDY8o5ExgVTPNsRFJJIHHse4NriZ5/R6lYqG40cMI2wHpCeYzSrSxKredbM4pOFPZy+DOIXf5Ma58PxyPy53sZ6sb0jhAoSknSjVdJ9LthEjNKMdRphUrjAgdkB42DQoSoGon00FH9qlxurYfSvOEtqfu746EBEoNA89UBkT31WI2Mf/LmrH2L9oJE1GsUdDZR37MbR3ak63tLpNINR8aIFQyM6tN+0QSqs1tMuYI7uLKy1A7K7jFQrHi5kp5mCkNR3ACeXDhHEpwDWWoAgWER3iGF+vOerJerbdZacqa9xzCH1nvP2ZpkQg=</latexit>Z<latexit sha1_base64=\"yC9X/vIczvf0cNc9NaHz45Lo31s=\">AAAB6HicbZC7SgNBFIbPxluMt6ilIItBSBV2LaKdARvLBMwFkxBmJ2eTMbOzy8ysEJaUVjYWitj6ANZ5DjufwZdwcik08YeBj/8/hznneBFnSjvOl5VaWV1b30hvZra2d3b3svsHNRXGkmKVhjyUDY8o5ExgVTPNsRFJJIHHse4NriZ5/R6lYqG40cMI2wHpCeYzSrSxKredbM4pOFPZy+DOIXf5Ma58PxyPy53sZ6sb0jhAoSknSjVdJ9LthEjNKMdRphUrjAgdkB42DQoSoGon00FH9qlxurYfSvOEtqfu746EBEoNA89UBkT31WI2Mf/LmrH2L9oJE1GsUdDZR37MbR3ak63tLpNINR8aIFQyM6tN+0QSqs1tMuYI7uLKy1A7K7jFQrHi5kp5mCkNR3ACeXDhHEpwDWWoAgWER3iGF+vOerJerbdZacqa9xzCH1nvP2ZpkQg=</latexit>Z\u2026A) Prompt-based adaptation, or B) Job classi\ufb01er-based adaptationReplaced with one learned vector\nC) Mixture-based adaptation\u2026<latexit", "mimetype": "text/plain", "start_char_idx": 25837, "end_char_idx": 28566, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e759f545-6501-4a67-84a6-f026dd5c6e9d": {"__data__": {"id_": "e759f545-6501-4a67-84a6-f026dd5c6e9d", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "doc_id:0", "node_type": "4", "metadata": {}, "hash": "9e241bbb55a81e809b01f83a00b7499b39b163a62ada3eb1b120a46b11886a36", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "260566b6-43d9-46bf-a1a0-532055392d9f", "node_type": "1", "metadata": {}, "hash": "0b061e0ab070e759c90075b78ed08a52d200073aa731cb45c94df1e326de7674", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "79e4b428-1895-4c24-b228-b7890283717d", "node_type": "1", "metadata": {}, "hash": "870f64c017c1043a4808eb1b96ff03d26616babdd2959e0a42ee91781503df97", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Prompt-based adaptation, or B) Job classi\ufb01er-based adaptationReplaced with one learned vector\nC) Mixture-based adaptation\u2026<latexit sha1_base64=\"ZoBKuE7P69Fe4FstEBqOVIcwRL0=\">AAAB+HicbVDLSsNAFJ20Pmp9NCqu3AwWQRBK4qK6LLhxWcE+oClhMp20QyeTMHMj1NAvceNCEbf+gb/gQnDlp+j0sdDWAxcO59zLvfcEieAaHOfTyuVXVtfWCxvFza3tnZK9u9fUcaooa9BYxKodEM0El6wBHARrJ4qRKBCsFQwvJ37rlinNY3kDo4R1I9KXPOSUgJF8u3TqEZEMiD/0gEdM+3bZqThT4GXizkm5lv/4fjv4YnXffvd6MU0jJoEKonXHdRLoZkQBp4KNi16qWULokPRZx1BJzJJuNj18jI+N0sNhrExJwFP190RGIq1HUWA6IwIDvehNxP+8TgrhRTfjMkmBSTpbFKYCQ4wnKeAeV4yCGBlCqOLmVkwHRBEKJquiCcFdfHmZNM8qbrVSvXbLNQfNUECH6AidIBedoxq6QnXUQBSl6B49oifrznqwnq2XWWvOms/soz+wXn8ATKCXPg==</latexit>+\u21b5k\u21e5\n<latexit sha1_base64=\"ZoBKuE7P69Fe4FstEBqOVIcwRL0=\">AAAB+HicbVDLSsNAFJ20Pmp9NCqu3AwWQRBK4qK6LLhxWcE+oClhMp20QyeTMHMj1NAvceNCEbf+gb/gQnDlp+j0sdDWAxcO59zLvfcEieAaHOfTyuVXVtfWCxvFza3tnZK9u9fUcaooa9BYxKodEM0El6wBHARrJ4qRKBCsFQwvJ37rlinNY3kDo4R1I9KXPOSUgJF8u3TqEZEMiD/0gEdM+3bZqThT4GXizkm5lv/4fjv4YnXffvd6MU0jJoEKonXHdRLoZkQBp4KNi16qWULokPRZx1BJzJJuNj18jI+N0sNhrExJwFP190RGIq1HUWA6IwIDvehNxP+8TgrhRTfjMkmBSTpbFKYCQ4wnKeAeV4yCGBlCqOLmVkwHRBEKJquiCcFdfHmZNM8qbrVSvXbLNQfNUECH6AidIBedoxq6QnXUQBSl6B49oifrznqwnq2XWWvOms/soz+wXn8ATKCXPg==</latexit>+\u21b5k\u21e5\n<latexit sha1_base64=\"rvY7URDetHJ3uMUQZv0k44XFelM=\">AAAB+HicbVDLSsNAFJ1YH7U+GhVXbgaLIAgl6aK6LLhxWcE+oCnhZjpph04mYWYi1NAvceNCEbf+gb/gQnDlp+j0sdDWAxcO59zLvfcECWdKO86ntZJbXVvfyG8WtrZ3dov23n5TxakktEFiHst2AIpyJmhDM81pO5EUooDTVjC8nPitWyoVi8WNHiW0G0FfsJAR0Eby7eKZBzwZgF/xNIuo8u2SU3amwMvEnZNSLffx/Xb4Reu+/e71YpJGVGjCQamO6yS6m4HUjHA6LnipogmQIfRpx1ABZkk3mx4+xidG6eEwlqaExlP190QGkVKjKDCdEeiBWvQm4n9eJ9XhRTdjIkk1FWS2KEw51jGepIB7TFKi+cgQIJKZWzEZgASiTVYFE4K7+PIyaVbKbrVcvXZLNQfNkEdH6BidIhedoxq6QnXUQASl6B49oifrznqwnq2XWeuKNZ85QH9gvf4A9NeXBQ==</latexit>+\u21b52\u21e5\n<latexit sha1_base64=\"rvY7URDetHJ3uMUQZv0k44XFelM=\">AAAB+HicbVDLSsNAFJ1YH7U+GhVXbgaLIAgl6aK6LLhxWcE+oCnhZjpph04mYWYi1NAvceNCEbf+gb/gQnDlp+j0sdDWAxcO59zLvfcECWdKO86ntZJbXVvfyG8WtrZ3dov23n5TxakktEFiHst2AIpyJmhDM81pO5EUooDTVjC8nPitWyoVi8WNHiW0G0FfsJAR0Eby7eKZBzwZgF/xNIuo8u2SU3amwMvEnZNSLffx/Xb4Reu+/e71YpJGVGjCQamO6yS6m4HUjHA6LnipogmQIfRpx1ABZkk3mx4+xidG6eEwlqaExlP190QGkVKjKDCdEeiBWvQm4n9eJ9XhRTdjIkk1FWS2KEw51jGepIB7TFKi+cgQIJKZWzEZgASiTVYFE4K7+PIyaVbKbrVcvXZLNQfNkEdH6BidIhedoxq6QnXUQASl6B49oifrznqwnq2XWeuKNZ85QH9gvf4A9NeXBQ==</latexit>+\u21b52\u21e5\n<latexit sha1_base64=\"/hIatESGxW7y6US6Az4TZbyHk9M=\">AAAB9XicbVDJSgNBEK1JXGLcouLJS2MQPIUZD9FjwIvHCGaBzBhqOj1Jk56F7h4lDPkPLx4U8eo3+AseBE9+inaWg0YfFDzeq6Kqnp8IrrRtf1i5/NLyymphrbi+sbm1XdrZbao4lZQ1aCxi2fZRMcEj1tBcC9ZOJMPQF6zlD88nfuuGScXj6EqPEuaF2I94wClqI127KJIBdh1X85CpbqlsV+wpyF/izEm5ln//et3/ZPVu6c3txTQNWaSpQKU6jp1oL0OpORVsXHRTxRKkQ+yzjqERmiVeNr16TI6M0iNBLE1FmkzVnxMZhkqNQt90hqgHatGbiP95nVQHZ17GoyTVLKKzRUEqiI7JJALS45JRLUaGIJXc3EroACVSbYIqmhCcxZf/kuZJxalWqpdOuWbDDAU4gEM4BgdOoQYXUIcGUJBwBw/waN1a99aT9TxrzVnzmT34BevlGxMUlp4=</latexit>\u21b51\u21e5\n<latexit", "mimetype": "text/plain", "start_char_idx": 28436, "end_char_idx": 31272, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "79e4b428-1895-4c24-b228-b7890283717d": {"__data__": {"id_": "79e4b428-1895-4c24-b228-b7890283717d", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "doc_id:0", "node_type": "4", "metadata": {}, "hash": "9e241bbb55a81e809b01f83a00b7499b39b163a62ada3eb1b120a46b11886a36", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e759f545-6501-4a67-84a6-f026dd5c6e9d", "node_type": "1", "metadata": {}, "hash": "8e7c219557ac5b01c5eed0ae9a0876d1802dccd0fbd313f481213d00ef348c4d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e695cd98-d5b8-4f65-8837-e3d1c29597cc", "node_type": "1", "metadata": {}, "hash": "9d9638c90c90c389475338d97e59202fc3f5c6f3fac40d17b0ad5c700f18fb3c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "sha1_base64=\"/hIatESGxW7y6US6Az4TZbyHk9M=\">AAAB9XicbVDJSgNBEK1JXGLcouLJS2MQPIUZD9FjwIvHCGaBzBhqOj1Jk56F7h4lDPkPLx4U8eo3+AseBE9+inaWg0YfFDzeq6Kqnp8IrrRtf1i5/NLyymphrbi+sbm1XdrZbao4lZQ1aCxi2fZRMcEj1tBcC9ZOJMPQF6zlD88nfuuGScXj6EqPEuaF2I94wClqI127KJIBdh1X85CpbqlsV+wpyF/izEm5ln//et3/ZPVu6c3txTQNWaSpQKU6jp1oL0OpORVsXHRTxRKkQ+yzjqERmiVeNr16TI6M0iNBLE1FmkzVnxMZhkqNQt90hqgHatGbiP95nVQHZ17GoyTVLKKzRUEqiI7JJALS45JRLUaGIJXc3EroACVSbYIqmhCcxZf/kuZJxalWqpdOuWbDDAU4gEM4BgdOoQYXUIcGUJBwBw/waN1a99aT9TxrzVnzmT34BevlGxMUlp4=</latexit>\u21b51\u21e5Replaced with a mixture of the learned vectors\nFigure 2: Method overview. Left) At training time, we employ SVF and RL to learn the \u201cexpert\u201d\nvectors z\u2019s that scale the singular values of the weight matrices. Right) At inference time, we propose\nthree distinct methods to adaptively select/combine the learned expert vectors.\nSingular value fine-tuning is a key building block in Transformer2. It offers an extremely efficient\nparameterization for fine-tuning and provides inherent compositionality for adaptation. Conven-\ntional fine-tuning techniques often aim to augment pre-trained models with new capabilities by mod-\nifying their weight matrices. However, in large-scale transformers, these weights are already rich\nrepositories of abstracted knowledge, thanks to the breadth of the pre-training data and expansive\narchitectural design. In fact, as evidenced in much of the prior literature, the requisite capabilities\nfor solving many downstream tasks appear to already exist within these pre-trained models (Sharma\net al., 2023). Therefore, instead of seeking to add new features, an efficient fine-tuning approach\nshould focus on making these latent capabilities more expressible. Motivated by these considera-\n4\nPreprint\ntions, for any weight matrix W, SVF learns a simple vector z\u2208Rrthat provides targeted modifica-\ntions to each singular component of Windependently, yielding a new weight matrix W\u2032=U\u03a3\u2032V\u22ba,\nwhere \u03a3\u2032= \u03a3\u2297diag(z). This essential parameterization enjoys several benefits:\nNegligible parameters: Learning only a vector zfor each weight matrix allows for very efficient\nfine-tuning with orders of magnitudes fewer optimized parameters even when compared to prior\napproaches specifically designed for efficiency. For example, the widely popular LoRA approach\nrequires (m+n)\u00d7r\u2032learnable parameters per weight matrix, where r\u2032is a hyper-parameter that gen-\nerally needs to be set large enough for expressivity. While recent extensions, such LoRA-XS (Ba\u0142azy\net al., 2024), try to push efficiency even further, they often introduce limiting assumptions that curb\napplicability in several practical scenarios (see examples in Appendix C). In contrast, while SVF\nonly needs r= min( m, n)parameters, we show it empirically does not display the same shortcom-\nings thanks to working on a highly-meaning space provided by the latent expressiveness compressed\nin the weights of modern LLMs. SVF\u2019s scaling only the singular values may seem to lead to limited\nexpressiveness, we wish to point out that the ability to affect the weight matrix in a full-rank manner\ntechnically provides more information than low-rank approaches.\nHigh compositionality: Decomposing the weights in independent singular components makes the\nlearned zvectors highly composable and interpretable, opening numerous possibilities for adapta-\ntion via algebraic manipulations. Instead, LoRA-based methods inherently lack these properties. For\ninstance, even if two LoRAs learned on the same task were to learn exactly the same adjustments for\neachW, directly interpolating between their compressed AandBmatrices is unlikely to preserve\nany of their original behavior, given the countless number of equivalent parameter permutations they\nmight have converged to.\nPrincipled regularization: Exclusively modifying the magnitude of pre-existing singular compo-\nnents provides a principled and effective form of regularization. In practice, this property enables\nus to fine-tune for arbitrary downstream tasks with only hundreds of data points without the risk of\nsevere collapse or overfitting.\nEnd-to-end optimization with RL. We train a set of SVF vectors \u03b8z={z1,\u00b7\u00b7\u00b7, zN\u00d7M}to fine-\ntune an arbitrary language model \u03c0\u03b8Wparameterized by \u03b8Wwith RL, optimizing directly for task\nperformance. Here, \u03b8W={W1,\u00b7\u00b7\u00b7, WN\u00d7M}is the set of weight matrices, where Nis the number\nof layers and Mis the number of weight matrices to fine-tune per layer. We use the seminal RE-\nINFORCE algorithm (Williams, 1992) and label each generated answer yi(for the prompt xi\u2208D)\nwith a unitary reward based on its correctness r\u2208 {\u2212 1,1}. Inspired by related applications of RL\nfor optimizing LLMs (Ouyang et al., 2022), we regularize the REINFORCE objective by adding\na KL penalty for deviating from the original model\u2019s behavior, weighted by a small coefficient\n\u03bb\u2208R+. Thus, our final objective function can be written as:\nJ(\u03b8z) =E\u0002\nlog\u0000\n\u03c0\u03b8W\u2032(\u02c6yi|xi)\u0001\nr(\u02c6yi, yi)\u0003\n\u2212\u03bbDKL(\u03c0\u03b8W\u2032\u2225\u03c0\u03b8W), (1)\nwhere we use \u03c0\u03b8W\u2032to denote the resulting language model after substituting the original weight\nmatrices WwithW\u2032. While RL is generally considered less stable than next-token prediction ob-\njectives, we find the regularization properties of SVF avoid many of the failure modes of prior less-\nconstrained parameterizations (see Section 4.3). Thus, combining these complementary components\neffectively enables us to avoid relying on expensive fine-tuning procedures with large hand-designed\ndatasets as proxies, and directly maximize task performance end-to-end.\nIn general, SVF with RL puts lower requirement on the dataset it trains on. For example, LoRA\nfine-tuning requires \u201cexplaining texts\u201d to perform next token predictions, which puts a higher re-\nquirement on the dataset (e.g., imagine LoRA fine-tuning on a GSM8K dataset where no reasoning\ntext but only the final number is provided). This benefit allows SVF to be more general and effective.\nOne possible caveat SVF can face is the sparse rewards caused by a weak base model, which we\ndiscuss this further in Section 5.\nSelf-adaptation is a critical mechanism in nature that has established itself as a core guiding princi-\nple in modern system design (Kl \u00a8os et al., 2015). Our initial efforts toward self-adaptive foundation\nmodels focus on the inference stage of LLMs, where we devise a simple two-pass adaptation strat-\negy that combines Ksets of base \u201cexpert\u201d vectors z1:Ktrained with SVF to provide different kinds\nof capabilities (e.g., coding, math, etc). The mapping between a capability and the dataset we train\non can be acquired in the dataset\u2019s meta data. In the first inference pass, given a task or an individ-\nual input prompt, Transformer2executes the model and observes its test-time behavior to derive a\n5\nPreprint\nnewz\u2032vector tailored to its test-time conditions. This adapted z\u2032is then used in the second infer-\nence pass to provide an actual response with the newly adapted weights. The interaction between\nSVF-trained expert vectors and the adaptation strategies ensures seamless integration, where ex-\npert vectors provide modular capabilities, and the adaptation strategies dynamically determine and\ncompose the most suitable combination to address the input task. In this first work, we propose\nthree simple approaches to produce the vector z\u2032during the first inference pass, implementing self-\nadaption with distinct methods and requirements. Below, we provide an outline of each method and\nrefer to Appendix A for additional implementation details.\nA) Prompt engineering: Our most basic approach involves constructing a new \u201cadaptation\u201d prompt\nwhich we use to directly askthe LLM to categorize the input prompt.", "mimetype": "text/plain", "start_char_idx": 31273, "end_char_idx": 38930, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e695cd98-d5b8-4f65-8837-e3d1c29597cc": {"__data__": {"id_": "e695cd98-d5b8-4f65-8837-e3d1c29597cc", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "doc_id:0", "node_type": "4", "metadata": {}, "hash": "9e241bbb55a81e809b01f83a00b7499b39b163a62ada3eb1b120a46b11886a36", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "79e4b428-1895-4c24-b228-b7890283717d", "node_type": "1", "metadata": {}, "hash": "870f64c017c1043a4808eb1b96ff03d26616babdd2959e0a42ee91781503df97", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "99e3b3f8-9b2c-4e04-b4c6-80ad184be0dc", "node_type": "1", "metadata": {}, "hash": "bc9535d8f8dd669b17a33dbb5b1e91fbe79b723cc2e51cbea13594e348f0d71f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "This adapted z\u2032is then used in the second infer-\nence pass to provide an actual response with the newly adapted weights. The interaction between\nSVF-trained expert vectors and the adaptation strategies ensures seamless integration, where ex-\npert vectors provide modular capabilities, and the adaptation strategies dynamically determine and\ncompose the most suitable combination to address the input task. In this first work, we propose\nthree simple approaches to produce the vector z\u2032during the first inference pass, implementing self-\nadaption with distinct methods and requirements. Below, we provide an outline of each method and\nrefer to Appendix A for additional implementation details.\nA) Prompt engineering: Our most basic approach involves constructing a new \u201cadaptation\u201d prompt\nwhich we use to directly askthe LLM to categorize the input prompt. Based on its response, we\nthen extract one category out of the set of domain topics used to pre-train each SVF expert and,\nthus, we select the corresponding z\u2032directly from z1:K. In our adaptation prompt, we also explicitly\nprovide the option for a generic \u201cothers\u201d category, allowing the model to use its base weights in case\nno expert provides appropriate capabilities. We show the format used to construct the adaptation\nprompt in Figure 3.\nAnalyze the given question and classify it into one of four categories: \n'code', 'math', 'reasoning', or \u2018others\u2019. Follow these guidelines:\n\n1. Code: Questions asking for programming solutions...\n2. Math: Questions involving mathematical calculations...\n3. Reasoning: Questions requiring logical thinking....\n4. Others: Questions not clearly fit into above categories...\n\nInstructions:\n- Consider the primary focus, skills, and knowledge required to answer \nthe question.\n- If a question spans multiple categories, choose the most dominant one.\n- Provide your final classification within \\\\boxed{} notation. Example: \\\n\\boxed{reasoning}\n\nFormat your response as follows:\nClassification: \\\\boxed{category}\nFigure 3: Prompt based adaptation. Self-\nadaptation prompt used by Transformer2to\nclassify the task prompt into pre-defined cat-\negories.B) Classification expert: A direct extension of the\nprompt engineering approach comes from using a\nspecialized system to handle task identification. Fol-\nlowing the principles of self-adaptation, we ap-\nply SVF to fine-tune the base LLM itself to han-\ndle this task. In particular, we collect a dataset\nD={(x1,1,1),\u00b7\u00b7\u00b7,(xi,k, k),\u00b7\u00b7\u00b7} from the KSVF\ntraining tasks, where xi,kis the i-th example from\nthek-th expert task. Each tuple (xi,k, k)then forms\nan example to pre-train an additional job classifica-\ntion expert zclearned in the same fashion as the oth-\ners. During the first inference pass, we simply load\nzc, intending to improve the inherent task classifica-\ntion capabilities of the base model to select a more\nappropriate z\u2032to handle the input prompt.\nC) Few-shot adaptation: Our third approach leverages additional task information by assuming\nextended access to its test-time conditions beyond individual prompts. Our approach is inspired by\npopular few-shot prompting techniques, which have been shown to provide consistent performance\nimprovements and even allow LLMs to \u201cin-context\u201d learn tasks that were entirely unseen prior to\ninference (Brown, 2020). For each optimized W, our approach entails producing an entirely new\nz\u2032=PK\nk=1\u03b1kzkby linearly interpolating between the Klearned SVF vectors, each weighted by\nthe coefficients \u03b1k. We employ CEM to search over the possible values of each \u03b1kbased on the\nperformance on a set of \u201cfew-shot prompts\u201d, which are specifically held out from the rest of the\ntest prompts and used to evaluate CEM\u2019s population samples. In the case of multiple population\nsamples obtaining the same score on these held-out prompts, we break ties by favoring the one with\nthe highest average log-likelihood across its own generated correct answers. Crucially, we only need\nto perform this process once for each target task, avoiding the need to increase the length of each\nquestion prompt, a relevant downside of traditional few-shot prompting. We refer to Section A.4,\nfor additional details and an extended discussion of this final approach.\n4 E XPERIMENTS\nWe extensively evaluate Transformer2on multiple tasks and models with the purpose of: (1) as-\nsessing the efficiency and effectiveness of SVF; (2) demonstrating self-adaptiveness through the\nthree proposed adaptation strategies; (3) conducting in-depth analysis and ablation studies aimed at\nunderstanding and interpreting the properties of our new framework.\n4.1 E XPERIMENTAL SETUPS\nTo validate the generality of Transformer2we consider three pre-trained LLMs ranging across dif-\nferent model families and architecture sizes: L LAMA 3-8B-I NSTRUCT , M ISTRAL -7B-I NSTRUCT -\nV0.3, and L LAMA 3-70B-I NSTRUCT . For each model, we obtain three sets of SVF-trained zvec-\ntors to maximize performance for GSM8K (Cobbe et al., 2021), MBPP-pro (Austin et al., 2021),\n6\nPreprint\n0 100 200 300 400\nEpoch0.700.750.800.850.90ScoreMath\n0 20 40 60 800.600.650.700.750.800.85Coding\n0 50 100 1500.890.900.910.920.930.94Reasoning\n0 50 100 1500.400.450.500.550.600.65Vision Language\nTrain\nT est\nFigure 4: SVF learning curves. The dashed lines indicate the performance of L LAMA 3-8B-\nINSTRUCT on the test split of each task. SVF effectively fine-tunes to surpass the base performance.\nWhile we use the best validation score to select our checkpoint for evaluation (marked by red dots),\nwe present the entire training curve without early stopping to demonstrate SVF\u2019s learning capabili-\nties. Tasks with only hundreds of training samples like Coding and Reasoning were stopped early.\nIn our experiments, we update the parameters at the end of each epoch.\nand ARC-Easy (Clark et al., 2018), respectively. Additionally, we also train a set of zvectors\nfor L LAMA 3-8B-I NSTRUCT , when applied as the language backbone for TextVQA (Singh et al.,\n2019), in order to assess SVF\u2019s applicability to the vision-language modeling (VLM) domain. We\nprovide SVF\u2019s main learning curves on each of these tasks in Figure 4. Finally, we evaluate the\nfull Transformer2adaptation framework on four unseen tasks: MATH (Hendrycks et al., 2021),\nHumaneval (Chen et al., 2021), ARC-Challenge (Clark et al., 2018), and OKVQA (Marino et al.,\n2019). In all our adaptation experiments, we only consider experts obtained in the pure-language set-\ntings, assessing its test-time applicability even for the distinctive vision domain. Please refer to the\nAppendix A for additional details and a summary of the hyper-parameters used in the experiments.\n4.2 E XPERIMENTAL RESULTS\nSVF performance We provide results after training on each considered task with the L LAMA 3-\n8B-I NSTRUCT , MISTRAL -7B-I NSTRUCT -V0.3, and L LAMA 3-70B-I NSTRUCT base models in Ta-\nble 1. Remarkably, we find that SVF provides considerable and consistent performance gains across\nnearly all tasks and base models. Instead, LoRA experts yield smaller gains and even sporadic per-\nformance degradation. (These LoRA experts are trained with next token prediction. While we also\nhave LoRA experts trained with RL in Table 4, RL seems work less well with LoRA than with\nSVF.) This observed trend extends also to the vision-language domain, as fine-tuning L LAMA 3-\nLLAVA -NEXT-8B with SVF bolsters the base model\u2019s performance by over 39% (see Figure 5). To\nensure a fair comparison, we provide extensive ablations to both our model and the LoRA baseline\nconsidering different architecture and optimization objectives in Appendix 4.3). Due to its essential\nparameterization, we would like to note that training SVF requires considerably fewer resources,\nwith less than 10% of the training parameters of our LoRA implementation.\nAdaptation performance With the SVF trained zvectors, we assess the self-adaptation capability\nof Transformer2on unseen tasks. For a fair comparison with LoRA, we record the performance\nof this baseline using all checkpoints from the considered training tasks and report only its high-\nest performance for each of the test tasks. As shown in Table 2, all of our Transformer2adapta-\ntion strategies demonstrate improvements across all tasks for L LAMA 3-8B-I NSTRUCT base models,\nand in at least two out of three tasks for both M ISTRAL -7B-I NSTRUCT -V0.3 and L LAMA 3-70B-\nINSTRUCT . In contrast, even the best training LoRAs only provide marginal improvements on the\nTable 1: Fine-tuning results.", "mimetype": "text/plain", "start_char_idx": 38075, "end_char_idx": 46572, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "99e3b3f8-9b2c-4e04-b4c6-80ad184be0dc": {"__data__": {"id_": "99e3b3f8-9b2c-4e04-b4c6-80ad184be0dc", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "doc_id:0", "node_type": "4", "metadata": {}, "hash": "9e241bbb55a81e809b01f83a00b7499b39b163a62ada3eb1b120a46b11886a36", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e695cd98-d5b8-4f65-8837-e3d1c29597cc", "node_type": "1", "metadata": {}, "hash": "9d9638c90c90c389475338d97e59202fc3f5c6f3fac40d17b0ad5c700f18fb3c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "04087e1b-ca19-4a32-b2e9-2560057f7d1d", "node_type": "1", "metadata": {}, "hash": "b5bf514a3835044003c2b2270aa55159f609e5818b13ecdc8d11a60a78a211fa", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Adaptation performance With the SVF trained zvectors, we assess the self-adaptation capability\nof Transformer2on unseen tasks. For a fair comparison with LoRA, we record the performance\nof this baseline using all checkpoints from the considered training tasks and report only its high-\nest performance for each of the test tasks. As shown in Table 2, all of our Transformer2adapta-\ntion strategies demonstrate improvements across all tasks for L LAMA 3-8B-I NSTRUCT base models,\nand in at least two out of three tasks for both M ISTRAL -7B-I NSTRUCT -V0.3 and L LAMA 3-70B-\nINSTRUCT . In contrast, even the best training LoRAs only provide marginal improvements on the\nTable 1: Fine-tuning results. LLM performance on the test splits of math,\ncoding and reasoning. Normalized scores are in the parentheses.\nMethod GSM8K MBPP-Pro ARC-Easy\nLLAMA 3-8B-I NSTRUCT 75.89 (1.00) 64.65 (1.00) 88.59 (1.00)\n+ LoRA 77.18 (1.02) 67.68 (1.05) 88.97 (1.00)\n+ SVF (Ours) 79.15 (1.04) 66.67 (1.03) 89.56 (1.01)\nMISTRAL -7B-I NSTRUCT -V0.3 42.83 (1.00) 49.50 (1.00) 81.65 (1.00)\n+ LoRA 44.66 (1.04) 51.52 (1.04) 81.19 (0.98)\n+ SVF (Ours) 49.74 (1.16) 51.52 (1.04) 85.14 (1.04)\nLLAMA 3-70B-I NSTRUCT 85.29 (1.00) 80.81 (1.00) 89.10 (1.00)\n+ LoRA 77.26 (0.91) 68.69 (0.85) 88.55 (0.99)\n+ SVF (Ours) 88.32 (1.04) 80.81 (1.00) 88.47 (0.99)\nT extVQA OKVQA3035404550Llama3-8B\nLoRA\nSVF/Transformer2Figure 5: Results for\nthe VLM domain.\n7\nPreprint\nTable 2: Self-adaptation on unseen tasks. Normalized scores are in the parentheses.\nMethod MATH Humaneval ARC-Challenge\nLLAMA 3-8B-I NSTRUCT 3 24.54 (1.00) 60.98 (1.00) 80.63 (1.00)\n+ LoRA 24.12 (0.98) 52.44 (0.86) 81.06 (1.01)\n+ Transformer2(Prompt) 25.22 (1.03) 61.59 (1.01) 81.74 (1.01)\n+ Transformer2(Cls-expert) 25.18 (1.03) 62.80 (1.03) 81.37 (1.01)\n+ Transformer2(Few-shot) 25.47 (1.04) 62.99 (1.03) 82.61 (1.02)\nMISTRAL -7B-I NSTRUCT -V0.3 13.02 (1.00) 43.29 (1.00) 71.76 (1.00)\n+ LoRA 13.16 (1.01) 37.80 (0.87) 75.77 (1.06)\n+ Transformer2(Prompt) 11.86 (0.91) 43.90 (1.01) 72.35 (1.01)\n+ Transformer2(Cls-expert) 11.60 (0.89) 43.90 (1.01) 74.83 (1.04)\n+ Transformer2(Few-shot) 13.39 (1.03) 47.40 (1.09) 75.47 (1.05)\nLLAMA 3-70B-I NSTRUCT 40.64 (1.00) 78.66 (1.00) 87.63 (1.00)\n+ LoRA 25.40 (0.62) 73.78 (0.94) 83.70 (0.96)\n+ Transformer2(Prompt) 40.44 (1.00) 79.88 (1.02) 88.48 (1.01)\nARC-Challenge task and still significantly deteriorate performance on both MATH and Humaneval.\nThis discrepancy suggests that LoRA\u2019s parameterization and optimization might be particularly sen-\nsitive to overfitting, especially when trained with the smaller GSM8K and MBPP-Pro datasets, the\ntasks that provide information most related to MATH and Humaneval. In Figure 5, we find a sim-\nilar dichotomy in the OKVQA task, with the performance of the base L LAMA 3-L LAVA -NEXT-8B\nVLM only improving after applying Transformer2. We note that also in this setting, Transformer2\nperforms self-adaptation only from the expert vectors from GSM8K, MBPP-Pro, and ARC-Easy.\nThus, this result further underscores the high flexibility of self-adaptation, transferring knowledge\ncompressed for tasks entirely based on language even for unrelated vision-based problems.\nComparing the three proposed adaptation strategies, we highlight a clear monotonic trend \u2013 with\nmore involved strategies and additional information about the test-time condition, self-adaptation\nappears to be increasingly effective. In particular, Transformer2with few-shot self-adaptation is\nalmost always the highest-scoring method, providing notable improvements across all tested settings\nexcept for L LAMA 3-70B-I NSTRUCT @MATH, where we have only SVF-tuned half of the layers\ndue to our limited GPU resources. This trend shows that providing additional or different kinds\nof information seems to be highly beneficial to our framework, suggesting that Transformer2could\nprovide foundation models with new means to continually improve performance when deployed in\nlifelong settings.\nTable 3: Time cost of 2-pass\ninference in prompt adaptation\nstrategy of Transformer2for the\nentire problem set. 1st to 2nd pass\ninference time ratios are shown in\nparentheses.\nTask 1st (s) 2nd (s)\nMATH 42.64 (13%) 321.19\nHumaneval 2.76 (19%) 14.28\nARC-Challenge 13.40 (47%) 28.51Table 3 reports the inference time required by the prompt adap-\ntation strategy of Transformer2, with the time spent on solving\nthe entire problem set presented separately for the 1st and 2nd\npasses. Notice that the 2nd pass inference time is the time\nspent on solving the problems, and the 1st pass inference time\nis the time for self-adaptation, 1st to 2nd pass inference time\nratios are in the parentheses. While the additional inference\npass might appear to double the overall runtime, it is important\nto note that inference time primarily depends on the number of\ntokens generated. In our settings, it is O(n)where nis the\nlength of the input. ARC-challenge\u2019s cost ratio is large because they are single choice problems\nand therefore the cost of the 2nd pass is also O(n). In general settings, we think it is reasonable\nto assume this ratio to be closer to those of MATH and Humaneval. For a detailed discussion on\nimproving the efficiency of CEM few-shot adaptation methods, please see Appendix D\n4.3 A NALYSIS\nLastly, we analyze and discuss the properties of our adaptation strategies for which we provide\nextensions and further discussion Appendix B.\nAnalysis 1: Job dispatching accuracy In Figure 6 we provide the confusion matrices of our\nclassification-based adaptation strategies. These results validate the effectiveness of both our\nclassification-based adaptation strategies to match each prompt with experts trained in similar do-\nmains, as evidenced by the high values along the diagonals.", "mimetype": "text/plain", "start_char_idx": 45874, "end_char_idx": 51619, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "04087e1b-ca19-4a32-b2e9-2560057f7d1d": {"__data__": {"id_": "04087e1b-ca19-4a32-b2e9-2560057f7d1d", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "doc_id:0", "node_type": "4", "metadata": {}, "hash": "9e241bbb55a81e809b01f83a00b7499b39b163a62ada3eb1b120a46b11886a36", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "99e3b3f8-9b2c-4e04-b4c6-80ad184be0dc", "node_type": "1", "metadata": {}, "hash": "bc9535d8f8dd669b17a33dbb5b1e91fbe79b723cc2e51cbea13594e348f0d71f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "72b6f982-3f0c-454e-9e1f-8f64d255050a", "node_type": "1", "metadata": {}, "hash": "99e5b32fe738418d27554a7a50da6ad1a755382b884ef369282beff6e7fd521c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "In our settings, it is O(n)where nis the\nlength of the input. ARC-challenge\u2019s cost ratio is large because they are single choice problems\nand therefore the cost of the 2nd pass is also O(n). In general settings, we think it is reasonable\nto assume this ratio to be closer to those of MATH and Humaneval. For a detailed discussion on\nimproving the efficiency of CEM few-shot adaptation methods, please see Appendix D\n4.3 A NALYSIS\nLastly, we analyze and discuss the properties of our adaptation strategies for which we provide\nextensions and further discussion Appendix B.\nAnalysis 1: Job dispatching accuracy In Figure 6 we provide the confusion matrices of our\nclassification-based adaptation strategies. These results validate the effectiveness of both our\nclassification-based adaptation strategies to match each prompt with experts trained in similar do-\nmains, as evidenced by the high values along the diagonals. Furthermore, the results from L LAMA 3-\n8\nPreprint\nMath Code ReasoningMATH HUMANEVAL ACR-Challenge1.00 0.00 0.00\n0.04 0.96 0.00\n0.17 0.00 0.77Llama3-8B\nPrompt Engineering\nMath Code Reasoning0.95 0.00 0.05\n0.02 0.98 0.00\n0.03 0.00 0.97Llama3-8B\nClassification Expert\nMath Code Reasoning0.96 0.00 0.00\n0.00 0.99 0.00\n0.06 0.00 0.95Mistral-7B\nPrompt Engineering\nMath Code Reasoning0.99 0.00 0.01\n0.00 1.00 0.00\n0.04 0.00 0.95Mistral-7B\nClassification Expert\nMath Code Reasoning1.00 0.00 0.00\n0.01 0.99 0.00\n0.05 0.00 0.95Llama3-70B\nPrompt Engineering\nFigure 6: Confusion matrices. These matrices display the classification percentages, where rows\nrepresent the task classes (ground truth) and columns indicate the predicted categories. Some sam-\nples are misclassified as \u201cOthers,\u201d which is reflected in rows where the totals do not sum to one.\n8B-I NSTRUCT and M ISTRAL -7B-I NSTRUCT -V0.3 also show that using the classification expert\nconsistently provides higher classification accuracy than vanilla prompt engineering. While this dif-\nference could explain the higher performance of the relative self-adaptation strategy, we also note\nthat domain similarity might not be the only metric relevant to identifying the best expert for each\nprompt or task. To this end, we believe many further unexplored extensions could be explored in\nfuture work, using heuristics such as past expert performance or token-level analysis to further push\nour framework\u2019s scalability.\nAnalysis 2: Training tasks adaptation contribution In Figure 7, we show the normalized adap-\ntive coefficients akinterpolating between our SVF vectors learned via CEM for L LAMA 3-8B-\nINSTRUCT and M ISTRAL -7B-I NSTRUCT -V0.3 across all the unseen downstream tasks. Intuitively,\nwe find that the expert vectors from the training tasks sharing similar topics to the unseen ones are of-\nten the highest contributors to the produced adaptive weights. However, we observe that the MATH\ntask appears as an interesting exception, as the akfor the expert obtained from GSM8K training is\nactually the lowest out of the three in both models. We hypothesize this reflects the different nature\nof the mathematics competition problems from MATH as compared to the grade-school problems\nin GSM8K. In fact, not only is the difficulty of the MATH questions far beyond GSM8K, but a large\nportion of its problems also hinges mainly on logical reasoning, for which a task like ARC might\nactually be more aligned. Furthermore, we also note that the different zvectors appear to contribute\nmore uniformly to adaptation in the Llama model. This difference might indicate that, due to its\nhigher base performance, the Llama model does not need to rely on any particular set of skills as\nmuch as Mistral, and can harness more holistic benefits from self-adaptation. Note that applying\nakuniformly is not a universal solution for leveraging expert vectors. This becomes evident when\nwe look at different model and task combinations (e.g. applying akuniformly on L LAMA 3-8B-\nINSTRUCT for MATH tasks only achieves 24.47, while Transformer2(Few-shot) achieves 25.47).\nAnalysis 3: Ablation studies\nModule sensitivity: We first compare the performance of SVF when it is applied to different modules\n(see trials 1-3). Under consistent conditions, both individual MLP and attention updates improve\nperformance, with MLP updates resulting in more pronounced gains. Simultaneous updates to both\nmodule types yield even more significant enhancements.\nObjective function: We are interested in the performance impact from different objective functions,\nand we compare the RL objective with next-token prediction loss (see trials 2 and 4). For the latter,\nwe use instruction fine-tuning with official GSM8K solutions as target tokens. Results show clear\nperformance gains with RL, demonstrating its effectiveness in task-specific fine-tuning. Conversely,\nnext-token prediction even hinders performance. This highlights RL\u2019s ability to handle cases lacking\ndetailed solutions, suggesting its superiority in this context.\nSVF vs LoRA: Finally, we also evaluate LoRA using the RL objective (see trials 2 and 5). A sig-\nnificant performance disparity is observed, primarily attributed to the severe instability of the LoRA\ntraining process. Despite exploring a wide range of learning rates, LoRA\u2019s performance consistently\nlagged behind. For further illustrations, see Figure 9 in the appendix.\nAnalysis 4: Cross-model compatibility Finally, we explore the potential for our self-adaptation\nframework to be applied across different LLMs . In particular, we evaluate whether the SVF ex-\npert vectors trained on L LAMA 3-8B-I NSTRUCT can benefit M ISTRAL -7B-I NSTRUCT -V0.3, and\nwhether we can perform adaptation across the expert vectors of these two models. We present our\nmain findings in Table 5 and refer to Appendix B for additional detailed results. Surprisingly, we\nfind that positive transfer occurs across the two models, with visible benefits in 2 out of 3 tasks. We\n9\nPreprint\nTable 4: Ablation studies. We fine-tune L LAMA 3-8B-I NSTRUCT on the GSM8K training split with\ndifferent settings and the results on the test split along with zero-shot transfer results on MATH.\n# Method Objective Function Module #Params ( \u2193) GSM8K ( \u2191) MATH ( \u2191)\n0 LLAMA-3-8B-I NSTRUCT 75.89 (1.00) 24.54 (1.00)\n1 SVF Policy gradient MLP 0.39M 78.62 (1.04) 24.20 (0.99)\n2 SVF Policy gradient attention 0.16M 76.19 (1.00) 24.20 (0.99)\n3 SVF Policy gradient MLP + attention 0.58M 79.23 (1.04) 25.04 (1.04)\n4 SVF Next token pred attention 0.16M 60.50 (0.80) 18.52 (0.75)\n5 LoRA Policy gradient attention 6.82M 57.92 (0.76) 15.72 (0.64)\n6 LoRA Next token pred attention 6.82M 77.18 (0.98) 24.12 (0.96)\n7 LoRA Next token pred MLP + attention 35.13M 75.66 (0.96) 22.12 (0.91)\nTable 5: Cross-model zvector transfer. Results from transferring the expert vectors trained on\nLLAMA 3-8B-I NSTRUCT to M ISTRAL -7B-I NSTRUCT -V0.3 with cross model few-shot adaptation.\nMethod MATH Humaneval ARC-Challenge\nSVF training task GSM8K MBPP-pro ARC-Easy\nMISTRAL -7B-I NSTRUCT -V0.3 13.02 (1.00) 43.29 (1.00) 71.76 (1.00)\n+ Llama SVF (ordered \u03c3i) 11.96 (0.92) 45.12 (1.04) 72.01 (1.00)\n+ Llama SVF (shuffled \u03c3i) 10.52 (0.81) 40.24 (0.93) 70.82 (0.99)\n+ Few-shot adaptation (cross-model) 12.65 (0.97) 46.75 (1.08) 75.64 (1.05)\nnote these improvements are due to the inherent ordering of the SVF parameterization, as randomly\nshuffling each SVF vector before applying it to the Mistral model consistently degrades performance.", "mimetype": "text/plain", "start_char_idx": 50701, "end_char_idx": 58137, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "72b6f982-3f0c-454e-9e1f-8f64d255050a": {"__data__": {"id_": "72b6f982-3f0c-454e-9e1f-8f64d255050a", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "doc_id:0", "node_type": "4", "metadata": {}, "hash": "9e241bbb55a81e809b01f83a00b7499b39b163a62ada3eb1b120a46b11886a36", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "04087e1b-ca19-4a32-b2e9-2560057f7d1d", "node_type": "1", "metadata": {}, "hash": "b5bf514a3835044003c2b2270aa55159f609e5818b13ecdc8d11a60a78a211fa", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a3e4191a-0e12-4c91-a104-e6c0f485e15a", "node_type": "1", "metadata": {}, "hash": "18496eb4a1af621ff7aa65ed36ae38e4813c4b5f81bff82d8a03f07e460545e0", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "GSM8K\n25.8%\nMBPP26.2%Arc Easy 48.0%MATHLlama3-8B\nGSM8K\n31.1%\nMBPP36.2%Arc Easy\n32.8%\nMATHMistral-7B\nGSM8K 31.2%\nMBPP35.1%Arc Easy\n33.7%\nHumanEvalGSM8K\n33.3%\nMBPP64.1%Arc Easy\n2.6%\nHumanEval\nGSM8K\n19.3%\nMBPP30.0%Arc Easy 50.7%Arc\nChallengeGSM8K\n5.4%MBPP\n7.1%\nArc Easy87.5%Arc\nChallenge\nFigure 7: \u03b1klearned weights.This operation leads to notable performance degradation across\neach task. Finally, by performing few-shot adaptation using\nthe SVF vectors collected from both models, the performance\nof M ISTRAL -7B-I NSTRUCT -V0.3 further improves across the\nboard. We observe that these gains even surpass the best score\nfrom adapting M ISTRAL -7B-I NSTRUCT -V0.3 with allthe SVF\nvectors in the ARC-Challenge task reported in Table 2. While\nthese results appear promising, we note that the surprising com-\npatibility discovered through our naive transfer approach is po-\ntentially tied to the similarity between the architectures of the two\nconsidered LLMs. To this end, whether similar transfer can be\nreplicated with models of different scales remains an open re-\nsearch question that could open the doors to disentangling and\nrecycling task-specific skills for newer/larger models, with im-\nportant implications for democratization and sustainability.\n5 C ONCLUSION\nIn this paper, we introduced Transformer2, providing a novel blueprint toward realizing self-adaptive\nLLMs. Within this framework, we first proposed SVF, offering superior performance than prior fine-\ntuning recipes, together with reduced costs, high compositionality, and overfitting regularization \u2013\nall crucial properties to achieve scalable self-adaptation. Leveraging a set of SVF experts as building\nblocks, we developed three effective strategies for self-adaptation, each offering unique benefits and\nmonotonic performance benefits with increasing access to the test-time conditions.\nWhile Transformer2demonstrates promising results, there remain exciting opportunities for future\nwork. One limitation is that the capabilities of SVF experts are tied to the latent components of the\nbase model. To address this, model merging offers a promising direction (Yu et al., 2024; Goddard\net al., 2024; Akiba et al., 2024), enabling specialized models to be combined into a single, more\ncapable model. Additionally, while our CEM-based adaptation effectively balances performance\nand efficiency, scaling to a large number of specialized domains may introduce increased one-time\ncomputational costs. However, this trade-off is offset by the benefits of improved performance and\nenhanced self-adaptation capabilities. Advances in model merging and efficient adaptation tech-\nniques have produced models dominating open leaderboards, making them strong candidates as\nbase models for Transformer2and opening new possibilities for adaptive LLMs.\n10\nPreprint\n6 A UTHOR CONTRIBUTIONS\nYujin Tang initiated the project. Qi Sun proposed the prompted-based method, developed the evalu-\nation framework, conducted the experiments, and provided contributions to writing. Edoardo Cetin\ndesigned the few-shot CEM adaptation strategy, performed the experiment, and made major con-\ntributions to manuscript writing. Yujin Tang proposed the core algorithm, conducted initial experi-\nments, made major contributions to the manuscript, and managed the project.\nREFERENCES\nTakuya Akiba, Makoto Shing, Yujin Tang, Qi Sun, and David Ha. Evolutionary optimization of\nmodel merging recipes. arXiv preprint arXiv:2403.13187 , 2024.\nJacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, Henryk Michalewski, David Dohan,\nEllen Jiang, Carrie Cai, Michael Terry, Quoc Le, et al. Program synthesis with large language\nmodels. arXiv preprint arXiv:2108.07732 , 2021.\nKlaudia Ba\u0142azy, Mohammadreza Banaei, Karl Aberer, and Jacek Tabor. Lora-xs: Low-rank adapta-\ntion with extremely small number of parameters. arXiv preprint arXiv:2405.17604 , 2024.\nTom B Brown. Language models are few-shot learners. arXiv preprint arXiv:2005.14165 , 2020.\nAlberto Cetoli. Fine-tuning llms with singular value decomposition. Hugging Face Blog, June\n2024. URL https://huggingface.co/blog/fractalego/svd-training . Ac-\ncessed: 2024-07-01.\nMark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde De Oliveira Pinto, Jared\nKaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. Evaluating large\nlanguage models trained on code. arXiv preprint arXiv:2107.03374 , 2021.\nPeter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick, and\nOyvind Tafjord. Think you have solved question answering? try arc, the ai2 reasoning challenge.\narXiv preprint arXiv:1803.05457 , 2018.\nKarl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser,\nMatthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al. Training verifiers to\nsolve math word problems. arXiv preprint arXiv:2110.14168 , 2021.\nElizabeth N Davison, Kimberly J Schlesinger, Danielle S Bassett, Mary-Ellen Lynall, Michael B\nMiller, Scott T Grafton, and Jean M Carlson. Brain network adaptability across task states. PLoS\ncomputational biology , 11(1):e1004029, 2015.\nYilun Du, Shuang Li, Antonio Torralba, Joshua B Tenenbaum, and Igor Mordatch. Improv-\ning factuality and reasoning in language models through multiagent debate. arXiv preprint\narXiv:2305.14325 , 2023.\nWilliam Fedus, Barret Zoph, and Noam Shazeer. Switch transformers: Scaling to trillion parameter\nmodels with simple and efficient sparsity. Journal of Machine Learning Research , 23(120):1\u201339,\n2022.\nCharles Goddard, Shamane Siriwardhana, Malikeh Ehghaghi, Luke Meyers, Vlad Karpukhin, Brian\nBenedict, Mark McQuade, and Jacob Solawetz. Arcee\u2019s mergekit: A toolkit for merging large\nlanguage models. arXiv preprint arXiv:2403.13257 , 2024.\nDan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song,\nand Jacob Steinhardt. Measuring mathematical problem solving with the math dataset. arXiv\npreprint arXiv:2103.03874 , 2021.\nEdward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang,\nand Weizhu Chen. Lora: Low-rank adaptation of large language models. arXiv preprint\narXiv:2106.09685 , 2021.\n11\nPreprint\nAlbert Q Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, Blanche Savary, Chris Bam-\nford, Devendra Singh Chaplot, Diego de las Casas, Emma Bou Hanna, Florian Bressand, et al.\nMixtral of experts. arXiv preprint arXiv:2401.04088 , 2024.\nJunmo Kang, Leonid Karlinsky, Hongyin Luo, Zhen Wang, Jacob Hansen, James Glass, David\nCox, Rameswar Panda, Rogerio Feris, and Alan Ritter. Self-moe: Towards compositional large\nlanguage models with self-specialized experts. arXiv preprint arXiv:2406.12034 , 2024.\nJared Kaplan, Sam McCandlish, Tom Henighan, Tom B Brown, Benjamin Chess, Rewon Child,\nScott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei. Scaling laws for neural language\nmodels. arXiv preprint arXiv:2001.08361 , 2020.\nVerena Kl \u00a8os, Thomas G \u00a8othel, and Sabine Glesner. Adaptive knowledge bases in self-adaptive sys-\ntem design. In 2015 41st Euromicro Conference on Software Engineering and Advanced Appli-\ncations , pp.", "mimetype": "text/plain", "start_char_idx": 58138, "end_char_idx": 65274, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a3e4191a-0e12-4c91-a104-e6c0f485e15a": {"__data__": {"id_": "a3e4191a-0e12-4c91-a104-e6c0f485e15a", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "doc_id:0", "node_type": "4", "metadata": {}, "hash": "9e241bbb55a81e809b01f83a00b7499b39b163a62ada3eb1b120a46b11886a36", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "72b6f982-3f0c-454e-9e1f-8f64d255050a", "node_type": "1", "metadata": {}, "hash": "99e5b32fe738418d27554a7a50da6ad1a755382b884ef369282beff6e7fd521c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "10b588cf-a3b1-40cc-9ca6-63c81c6601a3", "node_type": "1", "metadata": {}, "hash": "aee289b70a200fe4a04f6259e964f15f5e45de72c76ed46e42f307723aac04ab", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Self-moe: Towards compositional large\nlanguage models with self-specialized experts. arXiv preprint arXiv:2406.12034 , 2024.\nJared Kaplan, Sam McCandlish, Tom Henighan, Tom B Brown, Benjamin Chess, Rewon Child,\nScott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei. Scaling laws for neural language\nmodels. arXiv preprint arXiv:2001.08361 , 2020.\nVerena Kl \u00a8os, Thomas G \u00a8othel, and Sabine Glesner. Adaptive knowledge bases in self-adaptive sys-\ntem design. In 2015 41st Euromicro Conference on Software Engineering and Advanced Appli-\ncations , pp. 472\u2013478, 2015. doi: 10.1109/SEAA.2015.48.\nDawid Jan Kopiczko, Tijmen Blankevoort, and Yuki Markus Asano. Vera: Vector-based random\nmatrix adaptation. arXiv preprint arXiv:2310.11454 , 2023.\nVijay Lingam, Atula Tejaswi, Aditya Vavre, Aneesh Shetty, Gautham Krishna Gudur, Joy-\ndeep Ghosh, Alex Dimakis, Eunsol Choi, Aleksandar Bojchevski, and Sujay Sanghavi. Svft:\nParameter-efficient fine-tuning with singular vectors. arXiv preprint arXiv:2405.19597 , 2024.\nHaokun Liu, Derek Tam, Mohammed Muqeeth, Jay Mohta, Tenghao Huang, Mohit Bansal, and\nColin A Raffel. Few-shot parameter-efficient fine-tuning is better and cheaper than in-context\nlearning. Advances in Neural Information Processing Systems , 35:1950\u20131965, 2022.\nShih-Yang Liu, Chien-Yi Wang, Hongxu Yin, Pavlo Molchanov, Yu-Chiang Frank Wang, Kwang-\nTing Cheng, and Min-Hung Chen. Dora: Weight-decomposed low-rank adaptation. arXiv\npreprint arXiv:2402.09353 , 2024.\nLasse S Loose, David Wisniewski, Marco Rusconi, Thomas Goschke, and John-Dylan Haynes.\nSwitch-independent task representations in frontal and parietal cortex. Journal of Neuroscience ,\n37(33):8033\u20138042, 2017.\nKenneth Marino, Mohammad Rastegari, Ali Farhadi, and Roozbeh Mottaghi. Ok-vqa: A visual\nquestion answering benchmark requiring external knowledge. In Proceedings of the IEEE/cvf\nconference on computer vision and pattern recognition , pp. 3195\u20133204, 2019.\nLong Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong\nZhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. Training language models to fol-\nlow instructions with human feedback. Advances in neural information processing systems , 35:\n27730\u201327744, 2022.\nQwen Team. Qwen1.5-moe: Matching 7b model performance with 1/3 activated parameters, March\n2024. URL https://qwenlm.github.io/blog/qwen-moe/ . Blog post.\nSamyam Rajbhandari, Conglong Li, Zhewei Yao, Minjia Zhang, Reza Yazdani Aminabadi, Am-\nmar Ahmad Awan, Jeff Rasley, and Yuxiong He. Deepspeed-moe: Advancing mixture-of-experts\ninference and training to power next-generation ai scale. In International conference on machine\nlearning , pp. 18332\u201318346. PMLR, 2022.\nReuven Y Rubinstein and Dirk P Kroese. The cross-entropy method: a unified approach to com-\nbinatorial optimization, Monte-Carlo simulation, and machine learning , volume 133. Springer,\n2004.\nPratyusha Sharma, Jordan T Ash, and Dipendra Misra. The truth is in there: Improving reasoning\nin language models with layer-selective rank reduction. arXiv preprint arXiv:2312.13558 , 2023.\nAmanpreet Singh, Vivek Natarajan, Meet Shah, Yu Jiang, Xinlei Chen, Dhruv Batra, Devi Parikh,\nand Marcus Rohrbach. Towards vqa models that can read. In Proceedings of the IEEE/CVF\nconference on computer vision and pattern recognition , pp. 8317\u20138326, 2019.\n12\nPreprint\nChen Tianlong, Cheng Yu, Chen Beidi, Zhang Minjia, and Bansal Mohit. Mixture-of-experts in the\nera of llms: A new odyssey. ICML 2024 presentation slides, 2024. International Conference on\nMachine Learning (ICML).\nHanqing Wang, Zeguan Xiao, Yixia Li, Shuo Wang, Guanhua Chen, and Yun Chen. Milora:\nHarnessing minor singular components for parameter-efficient llm finetuning. arXiv preprint\narXiv:2406.09044 , 2024.\nRonald J Williams. Simple statistical gradient-following algorithms for connectionist reinforcement\nlearning. Machine learning , 8:229\u2013256, 1992.\nLe Yu, Bowen Yu, Haiyang Yu, Fei Huang, and Yongbin Li. Language models are super mario: Ab-\nsorbing abilities from homologous models as a free lunch. In Forty-first International Conference\non Machine Learning , 2024.\nCeyao Zhang, Kaijie Yang, Siyi Hu, Zihao Wang, Guanghe Li, Yihang Sun, Cheng Zhang, Zhaowei\nZhang, Anji Liu, Song-Chun Zhu, et al. Proagent: building proactive cooperative agents with large\nlanguage models. In Proceedings of the AAAI Conference on Artificial Intelligence , volume 38,\npp. 17591\u201317599, 2024.\nQingru Zhang, Minshuo Chen, Alexander Bukharin, Nikos Karampatziakis, Pengcheng He,\nYu Cheng, Weizhu Chen, and Tuo Zhao. Adalora: Adaptive budget allocation for parameter-\nefficient fine-tuning. arXiv preprint arXiv:2303.10512 , 2023.\nTong Zhu, Xiaoye Qu, Daize Dong, Jiacheng Ruan, Jingqi Tong, Conghui He, and Yu Cheng.\nLlama-moe: Building mixture-of-experts from llama with continual pre-training. arXiv preprint\narXiv:2406.16554 , 2024.\nMingchen Zhuge, Haozhe Liu, Francesco Faccio, Dylan R Ashley, R \u00b4obert Csord \u00b4as, Anand\nGopalakrishnan, Abdullah Hamdi, Hasan Abed Al Kader Hammoud, Vincent Herrmann,\nKazuki Irie, et al. Mindstorms in natural language-based societies of mind. arXiv preprint\narXiv:2305.17066 , 2023.\n13\nPreprint\nA I MPLEMENTATION DETAILS AND HYPER -PARAMETERS\nA.1 SVF TRAINING\nWe obtain the expert vectors zas the base components in Transformer2by training the SVF fine-\ntunes with a consistent recipe across the considered training tasks and language models. We divide\neach dataset to produce equal-sized training and validation splits. We then apply our RL-based\napproach, optimizing \u03b8zwith AdamW using a learning rate of 2\u00d710\u22123with cosine decay, a batch\nsize of 256, and gradient clipping. We employ early stopping and select the best \u03bb(the coefficient\nof the KL divergence term) based on validation performance. For the L LAMA 3-70B-I NSTRUCT\nand Vision tasks experiments, we apply the SVF on half of the layers to reduce memory usage\nwhile maintaining considerable performance improvement. During the training of L LAMA 3-8B-\nINSTRUCT on the vision language tasks, we apply a small negative reward (-0.1) for training stability.\nA.2 L ORA TRAINING\nBelow is an instruction that describes a task. Write a response that \nappropriately completes the request.\n\nNatalia sold clips to 48 of her friends in April, and then she sold half \nas many clips in May. How many clips did Natalia sell altogether in \nApril and May? \n\nNatalia sold 48/2 = <<48/2=24>>24 clips in May. Natalia sold 48+24 \n= <<48+24=72>>72 clips altogether in April and May. #### 72\nFigure 8: Sample problem and answer. Math data\nsample used for LoRA instruction fine-tuning, text in\nblue is the unmasked solution.We follow community best practices for\nLoRA fine-tuning, applying it to query and\nvalue projection layers with learning rates\naround 5\u00d710\u22125.", "mimetype": "text/plain", "start_char_idx": 64724, "end_char_idx": 71510, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "10b588cf-a3b1-40cc-9ca6-63c81c6601a3": {"__data__": {"id_": "10b588cf-a3b1-40cc-9ca6-63c81c6601a3", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "doc_id:0", "node_type": "4", "metadata": {}, "hash": "9e241bbb55a81e809b01f83a00b7499b39b163a62ada3eb1b120a46b11886a36", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a3e4191a-0e12-4c91-a104-e6c0f485e15a", "node_type": "1", "metadata": {}, "hash": "18496eb4a1af621ff7aa65ed36ae38e4813c4b5f81bff82d8a03f07e460545e0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8884f16c-868b-44d0-a923-adf0addb25ec", "node_type": "1", "metadata": {}, "hash": "768acb237f38de85e384000281f825c13e811c65f71d7ff24f7f24f0a2245c05", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "A.2 L ORA TRAINING\nBelow is an instruction that describes a task. Write a response that \nappropriately completes the request.\n\nNatalia sold clips to 48 of her friends in April, and then she sold half \nas many clips in May. How many clips did Natalia sell altogether in \nApril and May? \n\nNatalia sold 48/2 = <<48/2=24>>24 clips in May. Natalia sold 48+24 \n= <<48+24=72>>72 clips altogether in April and May. #### 72\nFigure 8: Sample problem and answer. Math data\nsample used for LoRA instruction fine-tuning, text in\nblue is the unmasked solution.We follow community best practices for\nLoRA fine-tuning, applying it to query and\nvalue projection layers with learning rates\naround 5\u00d710\u22125. We set 200 total itera-\ntions with a 256 global batch size for suffi-\ncient training. For feasible LoRA instruc-\ntion training, we collect solutions for all\ntraining tasks (GSM8K, MBPP, Arc-Easy,\nTextVQA) from official sources and ap-\npend them to question prompts. Table 8\nshows a sample math problem used for\nLoRA fine-tuning. Despite extensive hy-\nperparameter tuning, we often observe test\nperformance decay as discussed, which\ncan be attributed to the small number of training samples and potential model requirements for\ninstruction fine-tuning data (specifically, the highly detailed thinking process).\nA.3 H YPER PARAMETERS\nWe present a summary of the hyperparameters used in our experiments in Table 6. To optimize\nperformance, we conducted sweeps across several hyperparameters and selected the most effective\ncombination based on validation results. For SVF, our primary focus was on adjusting the KL\ncoefficient to enhance training stability. In the case of LoRA, we concentrated on sweeping the\nlearning rate and maximum gradient clip norm to identify optimal settings.\nA.4 F EW-SHOT ADAPTATION\nAs described in the main text, our few-shot adaptation approach entails producing an entirely new\nz\u2032=PK\nk=1\u03b1kzkfor each Wby linearly interpolating between the Klearned SVF vectors, each\nweighted by the coefficients \u03b1\u2208RK. We employ CEM to search for \u03b1k\u2019s based on the performance\non the few-shot prompts, which are specifically held out from the rest of the test prompts and used\nto obtain the elite set at each iteration. In the case of multiple sample solutions obtaining the same\nscore on these held-out samples, we break ties by choosing the sample solution with the highest\naverage log-likelihood across the tokens of its generated correct answers.\nIn all of our main experiments, we reserve only 10 samples of data for self-adaptation and perform up\nto 100 CEM iterations. For each setting, we consider both per-layer and per-vector adaptation, where\nthe latter strategy has the advantage of greatly simplifying search (as we only have 3 \u03b1coefficients).\nMoreover, we experiment with both normalizing across the \u03b1of different tasks (such that their sum\nwould be fixed to 1) or keeping them unconstrained. Due to the lack of a validation set, we simply\nreport the performance attained by our best sample from these test configurations at the end of\noptimization, on the remaining unseen samples for each task.\n14\nPreprint\nTable 6: Hyper-parameters used for SVF and LoRA training. We perform a sweep on certain\nsensitive hyper-parameters across methods for fair comparison.\nSVF Hyperparameters\nInitial mean value of z 0.1\nInitial variance value of z1\u00d710\u22123\nGlobal batch size 256\nLearning rate 2\u00d710\u22123\nClip max norm 1\u00d710\u22123\nKL coefficient \u03bb 0.0,0.1,0.2,0.3\nLoRA Hyperparameters\nRank 16\nLoRA alpha 32\nLoRA dropout 0.05\nGlobal batch size 256\nLearning rate 2\u00d710\u22124,5\u00d710\u22124,2\u00d710\u22125,5\u00d710\u22125,2\u00d710\u22126.5\u00d710\u22126,\nClip max norm 1\u00d710\u22123,1.0\nTable 7: Additional Comparison Experiment. Normalized scores are in the parentheses.\nMethod GSM8K MBPP-Pro ARC-Easy\nLLAMA 3-8B-I NSTRUCT 75.89 (1.00) 64.65 (1.00) 88.59 (1.00)\n+ IA3 78.01 (1.03) 67.68 (1.05)89.10 (1.01)\n+ DORA 78.09 (1.03) 64.65 (1.00) 89.14 (1.01)\n+ SVF(Ours) 79.15 (1.04) 66.67 (1.03) 89.56 (1.01)\nMethod MATH Humaneval ARC-Challenge\nLLAMA 3-8B-I NSTRUCT 24.54 (1.00) 60.98 (1.00) 80.63 (1.00)\n+ IA3 23.64 (0.96) 59.76 (0.98) 81.57 (1.01)\n+ DORA 24.44 (0.99) 52.44 (0.86) 81.14 (1.01)\n+ Transformer2(Prompt) 25.22 (1.03) 61.59 (1.01) 81.74 (1.01)\n+ Transformer2(Cls-expert) 25.18 (1.03) 62.80 (1.03) 81.37 (1.01)\n+ Transformer2(Few-shot) 25.47 (1.04) 62.99 (1.03) 82.61 (1.02)\nB A DDITIONAL RESULTS\nB.1 B ASELINE COMPARISON TO MORE PEFT M ETHODS\nWe conduct additional comparison studies against more parameter-efficient fine-tuning methods,\nincluding IA3Liu et al. (2022), DORA. Liu et al. (2024).\nAs Table 7 shows, SVF still outperforms other methods and shows promising generalized perfor-\nmance.\nB.2 I MPACT FROM NUMBER OF FEW -SHOTS\nTable 8: Few-shot adaptation scaling on the Arc-\nChallenge task. Performance varies with number of\nexamples.\nMethod Transformer2IA3100 steps IA31000 steps\nLLAMA 3-8B-I NSTRUCT 80.63 (1.00) 80.63 (1.00) 80.63 (1.00)\n+ 3-shot adaptation 82.18 (1.02) 81.83 (1.01) 79.01 (0.98)\n+ 5-shot adaptation 82.38 (1.02) 80.89 (1.00) 79.41 (0.98)\n+ 10-shot adaptation 82.61 (1.02) 82.00 (1.02) 79.78 (0.99)\n+ 20-shot adaptation 82.61 (1.02) 81.40 (1.01) 79.61 (0.99)We investigate the relationship between\nthe number of samples available for few-\nshot adaptation and downstream perfor-\nmance. Our analysis focused on the\ntest task where L LAMA 3-8B-I NSTRUCT\ndemonstrates the highest baseline perfor-\nmance, to prevent the potential for a null\nsignal in our CEM-based search.\nAs Table 8 shows, substantial benefits of\nour few-shot strategy are evident with as few as 3 to 5 test samples. Moreover, performance appears\nto plateau beyond 10 samples, underscoring how our essential and inherently regularized SVF pa-\n15\nPreprint\nrameterization effectively complements self-adaptation. This efficiency enables optimal use of data\nto enhance understanding of the test task.\nFor completeness, we have also conducted experiments with identical settings on IA3(Liu et al.,\n2022), another method that leverages few-shot examples. All experiments were conducted with full\nbatch size, a learning rate of 5\u00d710\u22125, with 100 and 1000 training steps.\nOur results indicate that the performance of IA3on the unseen test tasks is inferior to CEM-based\nadaptation for all numbers of few shots considered. We note that in our experiment, we have to\nconsiderably limit the number of optimization steps to avoid overfitting the 500,000 parameters of\nIA3on the few-shot samples. However, we believe overfitting might still be occurring to some\ndegree even after only 100 steps, as also validated by the model\u2019s perfect training accuracy on\nthis extremely small dataset. This limitation of fine-tuning-based adaptation highlights the superior\ngeneralization capability of our CEM-based adaptation approach in Transformer2.\nB.3 C ROSS -MODEL SVF TRANSFER ON THE TRAINING TASKS\nWe provide complementary results to Table 5 in the main text, where we analyze the SVF cross-\nmodel transfer performance from training on GSM8K, MBPP-pro, and ARC-Easy to our consid-\nered test tasks.", "mimetype": "text/plain", "start_char_idx": 70824, "end_char_idx": 77831, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8884f16c-868b-44d0-a923-adf0addb25ec": {"__data__": {"id_": "8884f16c-868b-44d0-a923-adf0addb25ec", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "doc_id:0", "node_type": "4", "metadata": {}, "hash": "9e241bbb55a81e809b01f83a00b7499b39b163a62ada3eb1b120a46b11886a36", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "10b588cf-a3b1-40cc-9ca6-63c81c6601a3", "node_type": "1", "metadata": {}, "hash": "aee289b70a200fe4a04f6259e964f15f5e45de72c76ed46e42f307723aac04ab", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "We note that in our experiment, we have to\nconsiderably limit the number of optimization steps to avoid overfitting the 500,000 parameters of\nIA3on the few-shot samples. However, we believe overfitting might still be occurring to some\ndegree even after only 100 steps, as also validated by the model\u2019s perfect training accuracy on\nthis extremely small dataset. This limitation of fine-tuning-based adaptation highlights the superior\ngeneralization capability of our CEM-based adaptation approach in Transformer2.\nB.3 C ROSS -MODEL SVF TRANSFER ON THE TRAINING TASKS\nWe provide complementary results to Table 5 in the main text, where we analyze the SVF cross-\nmodel transfer performance from training on GSM8K, MBPP-pro, and ARC-Easy to our consid-\nered test tasks. In Table 9, we show the results in the same transfer setting this time evaluating\nMISTRAL -7B-I NSTRUCT -V0.3 on the same training tasks where the L LAMA 3-8B-I NSTRUCT SVF\nvectors were obtained from. Overall, we recognize a similar trend, albeit with less consistent im-\nprovement from the original model (only in 1 out of 3 tasks), but still much higher performance than\nthe randomly shuffled baseline. These results further confirm that the canonical ordering of the SVF\nparameterization is key for cross-model transfer, highlighting once more its inherent suitability to\nempower self-adaptation.\nTable 9: Cross-model zVector Transfer. Results from transfering the SVF expert vectors trained\non L LAMA 3-8B-I NSTRUCT to M ISTRAL -7B-I NSTRUCT -V0.3 in the respective training tasks.\nMethod GSM8K MBPP-pro ARC-Easy\nMISTRAL -7B-I NSTRUCT -V0.3 42.83 (1.00) 49.50 (1.00) 81.65 (1.00)\n+ Llama SVF (ordered \u03c3i) 42.61 (0.99) 48.48 (0.98) 81.78 (1.00)\n+ Llama SVF (shuffled \u03c3i) 41.93 (0.98) 46.34 (0.94) 80.81 (0.99)\nB.4 T RAINING CURVE OF LORA AND POLICY GRADIENT\nFigure 9 gives the learning curves for LoRA training on the GSM8K task.\n0 50 100 150 200 250 300\nIterations0.550.600.650.700.750.80ScoreLearning Curve on GSM8K with Lora and Policy gradient\nTrain Accuracy\nT est Accuracy\nBase Model Performance\nFigure 9: Training LoRA with policy gradient. The dashed line shows the performance of\nLLAMA 3-8B-I NSTRUCT on the test split. LoRA collapses at the beginning of the training stage\nand fails to recover, leading to negative effects on test performance. We swept a wide range of learn-\ning rates (2\u00d710\u22124,5\u00d710\u22124, . . . , 2\u00d710\u22122,5\u00d710\u22122), and all learning curves were similar to the\none presented.\n16\nPreprint\nC PCA ON LLAMA 3AND MISTRAL\nTo investigate if the singular components that have the highest singular values are able to capture\nmost of the information of a weight matrix, we conducted Principle Component Analysis (PCA)\non the weight matrices in L LAMA 3-8B-I NSTRUCT and M ISTRAL -7B-I NSTRUCT -V0.3 (see Fig-\nures 10 and 11). In each figure, we plot the variance that is captured by the top rcomponents across\nall the layers in each type of modules for a weight matrix W\u2208Rm\u00d7n:\nratio=Pr\ni=1\u03c3iPmin(m,n)\nj=1\u03c3j\nHere, \u03c3\u2019s are the ordered (from largest to smallest) singular values on the weight matrix W. It is\neasy to see from the figures that when r= 256 , less than 50% of the variance is captured by these\ntop components on average. For the MLP layers, this fraction is even lower than 20%. On the\nother hand, the ranks adopted by LoRA-XS or similar methods are much less than 256, resulting\nin even more information loss and restrictions in their modeling power that relies mostly on these r\ncomponents.\n0.00.20.40.6q_proj\nr=16\nr=64\nr=256k_proj\n0.00.20.40.6v_proj o_proj\n0.00.20.40.6up_proj gate_proj\n0123456789101112131415161718192021222324252627282930310.00.20.40.6down_proj\nFigure 10: PCA of L LAMA 3-8B-I NSTRUCT .We show the ratio of the variance captured by the\ntoprsingular components on the y-axis, and the layer indices on the x-axis. Except for the Query,\nKey and Value projection matrices, small rvalues only capture a tiny fraction of variance in singular\nvalues in the parameter matrices.\nD E FFICIENCY CONSIDERATIONS AND IMPROVEMENTS\nTable 10: 3-shot and light variants Performance\nwith different inference-time adaptation budgets.\nMethod ARC-Challenge\nLLAMA 3-8B-I NSTRUCT 80.63 (1.00)\n+ CEM 10-shot adaptation 82.61 (1.02)\n+ CEM 3-shot (30% of prompts) 82.18 (1.02)\n+ CEM light (3% of prompts) 82.08 (1.02)Our CEM-based adaptation method involves\nrunning inference on a small number of sam-\nples for each target task (up to 10 in our ex-\nperiments). In a typical configuration, this pro-\ncess is relatively efficient: for example, our\nCEM-light approach (3-shot with 10 genera-\ntions) completes the ARC-Challenge task in ap-\nproximately 11 minutes. As shown in Table 10,\nthis lighter setup reduces the total number of samples to just 3% of the original setting while still\ndelivering substantial performance improvements over the base model.\n17\nPreprint\n0.00.20.40.60.8q_proj\nr=16\nr=64\nr=256k_proj\n0.00.20.40.60.8v_proj o_proj\n0.00.20.40.60.8up_proj gate_proj\n0123456789101112131415161718192021222324252627282930310.00.20.40.60.8down_proj\nFigure 11: PCA of M ISTRAL -7B-I NSTRUCT -V0.3. We show the ratio of the variance captured\nby the top rsingular components on the y-axis, and the layer indices on the x-axis. Except for the\nQuery, Key and Value projection matrices, small rvalues only capture a tiny fraction of variance in\nsingular values in the parameter matrices.\nWe acknowledge that CEM-based adaptation entails a trade-off between one-time overhead it spends\non searching the optimal combination weights for the SVF-tune vectors and performance. Increasing\nthe number of few-shot samples or the number of generations can yield higher performance, but this\ncomes at the cost of additional computational overhead. However, it is important to note that this\nadaptation cost is a one-time overhead per task. The cost-per-prompt diminishes significantly when\napplied to tasks with a large number of prompts.\nMoreover, in practical scenarios, CEM-based adaptation offers better scalability than few-shot\nprompting methods, which require increasing the length of every prompt, leading to much worse\nscaling as task sizes grow. In contrast, our method focuses on determining optimal expert vector\ncombinations efficiently and avoids repetitive inference-time costs. However, we note that the over-\nhead might be significant for tasks with very few prompts. Thus, the other adaptations methods\nmight be more appropriate for these particular settings.\nWe also highlight two immediate directions for improving efficiency:\n1. Reducing the number of few-shot samples: As shown in our ablation study in Ap-\npendix B.2, substantial benefits can be seen even in the 3-shot setting, which requires only\nevaluation of only 30% of the number of prompts per generation.\n2. Reducing the number of maximum generations: In the explored settings, the CEM param-\neters tend to converge early on, being very close to the final values after a much lower\nnumber of generations than 100.\nFinally, in this work we only considered CEM due to its simplicity, there exist several different\nevolution algorithms empirically showing better efficiency and convergence properties that we hope\nwill be explored in future research.\n18", "mimetype": "text/plain", "start_char_idx": 77066, "end_char_idx": 84264, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/metadata": {"757c2867-288a-4c98-98ec-61188b0a52e2": {"doc_hash": "58828ad7b162ce263ac162db77cfed0eb2169caf7cc2847a04275e6d2e17eaf7", "ref_doc_id": "doc_id:0"}, "923162c2-cef0-4b34-85ff-3155ad3a30ff": {"doc_hash": "9e92c52939b7c6a3cc3e1e96e3bf631de4d3fbad9b6fea2d9bdcde2b30c8ea96", "ref_doc_id": "doc_id:0"}, "edf6cc4a-57f5-475b-8fbc-438978ba2798": {"doc_hash": "122089d15885ef825bdf9c0a1fb47c3c8b872f41683dfc6ae19cab770716d01f", "ref_doc_id": "doc_id:0"}, "336b34d3-4aed-47d7-98cd-07aa170ed338": {"doc_hash": "1ecbf6430bbfc6a66e20390f6d0551286cd637ed38fc33c6b861cb2749bfcf1a", "ref_doc_id": "doc_id:0"}, "5e7b79c7-175f-4355-b915-20890b57462b": {"doc_hash": "1b2b392f8a9251b9b21f950a726cceda949a6f54b3e1c6ddb2f56508c50d6c6c", "ref_doc_id": "doc_id:0"}, "af4c0231-33c8-4dd3-a0b5-fa6c8e21ce21": {"doc_hash": "d56e8c0e78e03fd0bdb26ec6a722aa01aa64ba4067011b72556d7a0b58908fc4", "ref_doc_id": "doc_id:0"}, "260566b6-43d9-46bf-a1a0-532055392d9f": {"doc_hash": "0b061e0ab070e759c90075b78ed08a52d200073aa731cb45c94df1e326de7674", "ref_doc_id": "doc_id:0"}, "e759f545-6501-4a67-84a6-f026dd5c6e9d": {"doc_hash": "8e7c219557ac5b01c5eed0ae9a0876d1802dccd0fbd313f481213d00ef348c4d", "ref_doc_id": "doc_id:0"}, "79e4b428-1895-4c24-b228-b7890283717d": {"doc_hash": "870f64c017c1043a4808eb1b96ff03d26616babdd2959e0a42ee91781503df97", "ref_doc_id": "doc_id:0"}, "e695cd98-d5b8-4f65-8837-e3d1c29597cc": {"doc_hash": "9d9638c90c90c389475338d97e59202fc3f5c6f3fac40d17b0ad5c700f18fb3c", "ref_doc_id": "doc_id:0"}, "99e3b3f8-9b2c-4e04-b4c6-80ad184be0dc": {"doc_hash": "bc9535d8f8dd669b17a33dbb5b1e91fbe79b723cc2e51cbea13594e348f0d71f", "ref_doc_id": "doc_id:0"}, "04087e1b-ca19-4a32-b2e9-2560057f7d1d": {"doc_hash": "b5bf514a3835044003c2b2270aa55159f609e5818b13ecdc8d11a60a78a211fa", "ref_doc_id": "doc_id:0"}, "72b6f982-3f0c-454e-9e1f-8f64d255050a": {"doc_hash": "99e5b32fe738418d27554a7a50da6ad1a755382b884ef369282beff6e7fd521c", "ref_doc_id": "doc_id:0"}, "a3e4191a-0e12-4c91-a104-e6c0f485e15a": {"doc_hash": "18496eb4a1af621ff7aa65ed36ae38e4813c4b5f81bff82d8a03f07e460545e0", "ref_doc_id": "doc_id:0"}, "10b588cf-a3b1-40cc-9ca6-63c81c6601a3": {"doc_hash": "aee289b70a200fe4a04f6259e964f15f5e45de72c76ed46e42f307723aac04ab", "ref_doc_id": "doc_id:0"}, "8884f16c-868b-44d0-a923-adf0addb25ec": {"doc_hash": "768acb237f38de85e384000281f825c13e811c65f71d7ff24f7f24f0a2245c05", "ref_doc_id": "doc_id:0"}}, "docstore/ref_doc_info": {"doc_id:0": {"node_ids": ["757c2867-288a-4c98-98ec-61188b0a52e2", "923162c2-cef0-4b34-85ff-3155ad3a30ff", "edf6cc4a-57f5-475b-8fbc-438978ba2798", "336b34d3-4aed-47d7-98cd-07aa170ed338", "5e7b79c7-175f-4355-b915-20890b57462b", "af4c0231-33c8-4dd3-a0b5-fa6c8e21ce21", "260566b6-43d9-46bf-a1a0-532055392d9f", "e759f545-6501-4a67-84a6-f026dd5c6e9d", "79e4b428-1895-4c24-b228-b7890283717d", "e695cd98-d5b8-4f65-8837-e3d1c29597cc", "99e3b3f8-9b2c-4e04-b4c6-80ad184be0dc", "04087e1b-ca19-4a32-b2e9-2560057f7d1d", "72b6f982-3f0c-454e-9e1f-8f64d255050a", "a3e4191a-0e12-4c91-a104-e6c0f485e15a", "10b588cf-a3b1-40cc-9ca6-63c81c6601a3", "8884f16c-868b-44d0-a923-adf0addb25ec"], "metadata": {}}}}